{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292d7844",
   "metadata": {},
   "source": [
    "## Grammatical Gender Build Batch Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39dda17-d667-4b97-b0c4-e8dc8a5c3c1a",
   "metadata": {},
   "source": [
    "Решаем задачу поиска ошибки согласования рода.\n",
    "Будем предсказывать род слова по его контексту.\n",
    "Построен бандл.\n",
    "\n",
    "Хотим построить батч. \n",
    "\n",
    "В нем должны быть признаки pymorphy. Разумеется, без рода самого слова.\n",
    "Без slovnet'а потому что slovnet плохо работает на предложениях с ошибками.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433e8db-3a17-49ff-b43c-be9e2712b137",
   "metadata": {},
   "source": [
    "Посмотрим как работает CoreExtractor - сущность, которая достает из бандла признаки и строит единый датафрейм, в котором указаны все признаки слова. Умеет работать с любыми индексами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c218ef-19f2-4ec6-bda9-10874a72cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from yo_fluq_ds import *\n",
    "from tg.common.ml import batched_training as bt\n",
    "from tg.common import DataBundle, Loc\n",
    "from tg.common.ml.batched_training import IndexedDataBundle\n",
    "from tg.grammar_ru.ml.components.core_extractor.extractor import CoreExtractor\n",
    "from tg.grammar_ru.ml.components.plain_context_builder import PlainContextBuilder\n",
    "from tg.grammar_ru.ml.components.contextual_binding import ContextualBinding, ContextualNetworkType\n",
    "from tg.common.ml.batched_training import mirrors as btm\n",
    "from tg.common.ml.batched_training import Batcher\n",
    "from tg.grammar_ru.common import Separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626fd51f-c7bf-4178-b988-24fde39ab4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.common import DataBundle\n",
    "from tg.common.ml.batched_training import IndexedDataBundle\n",
    "\n",
    "db = DataBundle.load(Loc.data_cache_path/'bundles/grammatical_gender/toy')\n",
    "idb = IndexedDataBundle(db.index, db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "158b9046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_id  sentence_id  label    split\n",
       "sample_id                                      \n",
       "0                0            0      0  display\n",
       "1                1            0      1    train\n",
       "2                3            0      1    train\n",
       "3                5            0      0     test\n",
       "4                7            0      0     test"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c8655fc-675d-4b12-9719-a61c44ee347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>word</th>\n",
       "      <th>is_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>display</td>\n",
       "      <td>Штабс-капитан</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>П</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Н</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Нестеров</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>днях</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>районе</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>Желтиева</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Галиции</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>летящий</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>display</td>\n",
       "      <td>нашим</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id  label    split           word  is_target\n",
       "0        0            0      0  display  Штабс-капитан       True\n",
       "1        1            0      1    train              П       True\n",
       "2        3            0      1    train              Н       True\n",
       "3        5            0      0     test       Нестеров       True\n",
       "4        7            0      0     test           днях       True\n",
       "5       11            0      0    train         районе       True\n",
       "6       12            0      1     test       Желтиева       True\n",
       "7       15            0      1    train        Галиции       True\n",
       "8       17            0      0    train        летящий       True\n",
       "9       19            0      3  display          нашим       True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index.head(10).merge(\n",
    "    db.data_frames['src'][['word_id', 'word','is_target']], on='word_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e46912",
   "metadata": {},
   "source": [
    "##### Пример CoreExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9762bb8-60af-42f0-b9fb-d029b374cc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 08:42:58.748248+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-12-09 08:42:58.893487+00:00 INFO: Success\n",
      "2022-12-09 08:42:58.894250+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-12-09 08:42:59.004478+00:00 INFO: Success\n",
      "2022-12-09 08:42:59.005274+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-12-09 08:42:59.045672+00:00 INFO: Success\n",
      "2022-12-09 08:42:59.046903+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-12-09 08:42:59.077036+00:00 INFO: Success\n",
      "2022-12-09 08:42:59.077776+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-12-09 08:42:59.116513+00:00 INFO: Success\n"
     ]
    }
   ],
   "source": [
    "core = CoreExtractor()\n",
    "core.fit(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b925e63b-dd22-434e-8bee-22488e67463b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pymorphy_score</th>\n",
       "      <th>pymorphy_delta_score</th>\n",
       "      <th>pymorphy_alternatives</th>\n",
       "      <th>pymorphy_POS_NOUN</th>\n",
       "      <th>pymorphy_POS_ADJF</th>\n",
       "      <th>pymorphy_POS_VERB</th>\n",
       "      <th>pymorphy_POS_PRTF</th>\n",
       "      <th>pymorphy_POS_PRTS</th>\n",
       "      <th>pymorphy_POS_ADJS</th>\n",
       "      <th>pymorphy_animacy_inan</th>\n",
       "      <th>...</th>\n",
       "      <th>syntax_fixes_root_Picked</th>\n",
       "      <th>syntax_fixes_cycle_status_No</th>\n",
       "      <th>syntax_fixes_cycle_status_Broken</th>\n",
       "      <th>syntax_fixes_cycle_status_Yes</th>\n",
       "      <th>syntax_stats_descendants_relative</th>\n",
       "      <th>syntax_stats_children</th>\n",
       "      <th>syntax_stats_descendants</th>\n",
       "      <th>syntax_stats_sentence_length</th>\n",
       "      <th>syntax_stats_up_depth</th>\n",
       "      <th>syntax_stats_down_depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901142</td>\n",
       "      <td>0.949787</td>\n",
       "      <td>-0.964494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.231461</td>\n",
       "      <td>-0.065904</td>\n",
       "      <td>0.720987</td>\n",
       "      <td>1.253148</td>\n",
       "      <td>-0.880312</td>\n",
       "      <td>0.600570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.069591</td>\n",
       "      <td>-1.616324</td>\n",
       "      <td>6.928503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.314240</td>\n",
       "      <td>1.403946</td>\n",
       "      <td>0.541865</td>\n",
       "      <td>1.253148</td>\n",
       "      <td>-0.066655</td>\n",
       "      <td>-0.046574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.044473</td>\n",
       "      <td>-1.616324</td>\n",
       "      <td>6.534467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.645357</td>\n",
       "      <td>-1.177802</td>\n",
       "      <td>-1.039332</td>\n",
       "      <td>1.253148</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>-1.152873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pymorphy_score  pymorphy_delta_score  pymorphy_alternatives  \\\n",
       "sample_id                                                                \n",
       "0                0.901142              0.949787              -0.964494   \n",
       "1               -3.069591             -1.616324               6.928503   \n",
       "2               -3.044473             -1.616324               6.534467   \n",
       "\n",
       "           pymorphy_POS_NOUN  pymorphy_POS_ADJF  pymorphy_POS_VERB  \\\n",
       "sample_id                                                            \n",
       "0                        1.0                0.0                0.0   \n",
       "1                        1.0                0.0                0.0   \n",
       "2                        1.0                0.0                0.0   \n",
       "\n",
       "           pymorphy_POS_PRTF  pymorphy_POS_PRTS  pymorphy_POS_ADJS  \\\n",
       "sample_id                                                            \n",
       "0                        0.0                0.0                0.0   \n",
       "1                        0.0                0.0                0.0   \n",
       "2                        0.0                0.0                0.0   \n",
       "\n",
       "           pymorphy_animacy_inan  ...  syntax_fixes_root_Picked  \\\n",
       "sample_id                         ...                             \n",
       "0                            0.0  ...                       0.0   \n",
       "1                            1.0  ...                       0.0   \n",
       "2                            1.0  ...                       0.0   \n",
       "\n",
       "           syntax_fixes_cycle_status_No  syntax_fixes_cycle_status_Broken  \\\n",
       "sample_id                                                                   \n",
       "0                                   1.0                               0.0   \n",
       "1                                   1.0                               0.0   \n",
       "2                                   1.0                               0.0   \n",
       "\n",
       "           syntax_fixes_cycle_status_Yes  syntax_stats_descendants_relative  \\\n",
       "sample_id                                                                     \n",
       "0                                    0.0                          -0.231461   \n",
       "1                                    0.0                          -0.314240   \n",
       "2                                    0.0                          -0.645357   \n",
       "\n",
       "           syntax_stats_children  syntax_stats_descendants  \\\n",
       "sample_id                                                    \n",
       "0                      -0.065904                  0.720987   \n",
       "1                       1.403946                  0.541865   \n",
       "2                      -1.177802                 -1.039332   \n",
       "\n",
       "           syntax_stats_sentence_length  syntax_stats_up_depth  \\\n",
       "sample_id                                                        \n",
       "0                              1.253148              -0.880312   \n",
       "1                              1.253148              -0.066655   \n",
       "2                              1.253148               0.510644   \n",
       "\n",
       "           syntax_stats_down_depth  \n",
       "sample_id                           \n",
       "0                         0.600570  \n",
       "1                        -0.046574  \n",
       "2                        -1.152873  \n",
       "\n",
       "[3 rows x 151 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted = core.extract(idb)\n",
    "extracted.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f00c17-5508-43df-a4f7-658810de9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(extracted.columns)  # все признаки из pymorphy, slovnet...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30791cb4",
   "metadata": {},
   "source": [
    "##### ⚹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f5e69-8534-446a-aef2-ab8215001720",
   "metadata": {},
   "source": [
    "* Для каждого слова получили все признаки из pymorphy, slovnet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08039c7d-48b0-4d7a-b5b1-128e1c93ede7",
   "metadata": {},
   "source": [
    "* Нам необходим контекст слова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15527c-77cd-4b6c-8bd8-78e2c825c932",
   "metadata": {},
   "source": [
    "Будем использовать `PlainContextBuilder`.  Он построит двойной индекс.\n",
    "\n",
    "* хотим исключить само слово из контекста, поэтому `include_zero_offset=False`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd869e7c",
   "metadata": {},
   "source": [
    "#### Пример PlainContextBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fb1077c-4498-448a-af52-32a64dfd1de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>another_word_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th>offset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">55755</th>\n",
       "      <th>2</th>\n",
       "      <td>99930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">55784</th>\n",
       "      <th>1</th>\n",
       "      <td>99974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247491 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  another_word_id\n",
       "sample_id offset                 \n",
       "0         1                     1\n",
       "          2                     2\n",
       "          3                     3\n",
       "          4                     4\n",
       "          5                     5\n",
       "...                           ...\n",
       "55755     2                 99930\n",
       "          3                 99931\n",
       "55784     1                 99974\n",
       "          2                 99975\n",
       "          3                 99976\n",
       "\n",
       "[247491 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_context_builder = PlainContextBuilder(include_zero_offset=False,\n",
    "                          left_to_right_contexts_proportion=1)\n",
    "contexts = plain_context_builder.build_context(idb, context_size=5)\n",
    "contexts  # TODO в конце offset in [1,2,3]; 4, 5?\n",
    "# sample_id ≠ word_id; sample_id - нумерация от 0 до len(db.index). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b064ed1",
   "metadata": {},
   "source": [
    "#### ⚹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394440ba",
   "metadata": {},
   "source": [
    "#### WordContextAssemblyPoint (~ ContextualBinding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c68dbb",
   "metadata": {},
   "source": [
    "Задача AssemblyPoint'a (он же ContextualBinding) - порождать экстракторами батчи в том виде, в котором они будут приняты сетью. Для LSTM будет 3d-тензор. Для Plain-сети будет плоский датафрейм.\n",
    "\n",
    "AssemblyPoint вызовет ContextBuilder, получит контексты (датафрейм с двойным индексом).\n",
    "Затем вызовет CoreExtractor, который добавит признаки всех слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395fd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tg.grammar_ru.ml.components.contextual_binding import ContextualBinding, ContextualNetworkType\n",
    "\n",
    "plain_context = ContextualBinding(\n",
    "    name='plain_context',\n",
    "    context_length=3,\n",
    "    network_type=ContextualNetworkType.Plain,\n",
    "    hidden_size=[30],\n",
    "    context_builder=plain_context_builder, \n",
    "    extractor=CoreExtractor(join_column='another_word_id'),\n",
    "    debug=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92aa50",
   "metadata": {},
   "source": [
    "**Пояснение:**\n",
    "По умолчанию CoreExtractor пытается мерджить по word_id. В нашем случае CoreExtractor отработает после создания PlainContextBuilder'ом двойного индекса. \n",
    "Для добавления признаков слов из контекста будем join'ить по столбцу another_word_id. Поэтому join_column='another_word_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae35c19",
   "metadata": {},
   "source": [
    "Для создания согласованных экстракторов и сетей у AssemblyPoint есть методы create_extractor и create_network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc9aac",
   "metadata": {},
   "source": [
    "У такой сети на последнем слое hidden_size нейронов. Ее выход можно подать в другую сеть, которая будет выдавать вероятности классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afeb414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 08:43:01.029677+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-12-09 08:43:02.046955+00:00 INFO: Success\n",
      "2022-12-09 08:43:02.047747+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-12-09 08:43:02.691891+00:00 INFO: Success\n",
      "2022-12-09 08:43:02.692715+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-12-09 08:43:03.214637+00:00 INFO: Success\n",
      "2022-12-09 08:43:03.215368+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-12-09 08:43:03.619722+00:00 INFO: Success\n",
      "2022-12-09 08:43:03.620427+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-12-09 08:43:03.990518+00:00 INFO: Success\n"
     ]
    }
   ],
   "source": [
    "core_extractor = plain_context.create_extractor(task=None, bundle=idb)\n",
    "core_extractor.fit(idb)\n",
    "# not_batch = core_extractor.extract(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa95cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = plain_context.create_network_factory(\n",
    "    task=None, input=None)  # None это ок. это legacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8a14c",
   "metadata": {},
   "source": [
    "#### Batcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5c17e",
   "metadata": {},
   "source": [
    "Иногда нам нужны фичи контекстов нескольких слов. Например, в задаче поиска антецедентов это местоимение и два существительных - потенциальные антецеденты. Для каждого из этих слов создадим экстрактор (для каждого экстрактора будет отдельная голова нейросети). Batcher примет список этих экстракторов и создаст батч.\n",
    "\n",
    "`+` нам понадобится экстрагировать лейблы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59f8f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import Conventions\n",
    "from tg.common.ml import dft\n",
    "# экстрагирует лейблы. Получается one-hot df. Лейблы пойдут в loss function.\n",
    "\n",
    "\n",
    "def get_multilabel_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                       .build(Conventions.LabelFrame)\n",
    "                       .index()\n",
    "                       .apply(take_columns=['label'], transformer=dft.DataFrameTransformerFactory.default_factory())\n",
    "                       )\n",
    "    return label_extractor\n",
    "\n",
    "\n",
    "def test_extractor(extractor, bundle):\n",
    "    extractor.fit(bundle)\n",
    "    return extractor.extract(bundle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a3b06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 08:43:15.917579+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-12-09 08:43:15.941442+00:00 INFO: Success\n",
      "2022-12-09 08:43:15.942010+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-12-09 08:43:15.959976+00:00 INFO: Success\n",
      "2022-12-09 08:43:15.960501+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-12-09 08:43:15.969326+00:00 INFO: Success\n",
      "2022-12-09 08:43:15.969951+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-12-09 08:43:15.979490+00:00 INFO: Success\n",
      "2022-12-09 08:43:15.980056+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-12-09 08:43:15.996660+00:00 INFO: Success\n"
     ]
    }
   ],
   "source": [
    "batcher = Batcher(batch_size=10, extractors=[\n",
    "                  core_extractor, get_multilabel_extractor()])\n",
    "batch = batcher.fit_extract(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f0e209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['index'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b9addb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = factory.create_network(task=None, input=batch)\n",
    "# при создании сети необходим батч\n",
    "network(batch).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47229cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO tsa run_tarining. factory...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9e15e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e710e",
   "metadata": {},
   "source": [
    "Полные данные не помещаются в память локальной машины, но для инициализации сети нужно понять, сколько бывает классов в полных данных. Поэтому сеть инициализируется в BatchedTrainingTask, который выполняется на сервере. \n",
    "\n",
    "Создадим TaskFactory, отправим ее на сервер. Она подтянет данные, создаст BatchedTrainingTask и запустит его.\n",
    "\n",
    "`TaskFactory` из `tg.grammar_ru.ml.components.training_task_factory.torch_task_factory`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cb1d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def _update_sizes_with_argument(argument_name, argument, sizes, modificator):\n",
    "    if argument is None:\n",
    "        return sizes\n",
    "    elif isinstance(argument, torch.Tensor):\n",
    "        return modificator(sizes, argument.shape[1])\n",
    "    elif isinstance(argument, pd.DataFrame):\n",
    "        return modificator(sizes, argument.shape[1])\n",
    "    elif isinstance(argument, int):\n",
    "        return modificator(sizes, argument)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Argument {argument_name} is supposed to be int, Tensor or none, but was `{argument}`\")\n",
    "\n",
    "\n",
    "class FullyConnectedNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 sizes: List[int],\n",
    "                 input: Union[None, torch.Tensor, int] = None,\n",
    "                 output: Union[None, torch.Tensor, int] = None):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        sizes = _update_sizes_with_argument(\n",
    "            'input', input, sizes, lambda s, v: [v] + s)\n",
    "        sizes = _update_sizes_with_argument(\n",
    "            'output', output, sizes, lambda s, v: s + [v])\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(len(sizes) - 1):\n",
    "            self.layers.append(torch.nn.Linear(sizes[i], sizes[i + 1]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        X = input\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "            X = torch.sigmoid(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7189dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.common.ml.batched_training.torch.networks.extracting_network import FeedForwardNetwork\n",
    "\n",
    "class MyNetworkFactory:\n",
    "    def __init__(self, nn_head_factory):\n",
    "        self.nn_head_factory = nn_head_factory\n",
    "\n",
    "    def create_network(self, task, input):  # input is batch ~ sample\n",
    "        nn_head = self.nn_head_factory.create_network(task=None, input=input)\n",
    "        head_out = nn_head(input)\n",
    "        hidden_size = head_out.shape[1]\n",
    "        labels_count = input['label'].shape[1]\n",
    "        nn_tail = FullyConnectedNetwork(\n",
    "            sizes=[3], input=hidden_size, output=labels_count)\n",
    "        return FeedForwardNetwork(nn_head, nn_tail, torch.nn.Softmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f47dc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_network_factory = MyNetworkFactory(factory)\n",
    "assembled_network = assembled_network_factory.create_network(\n",
    "    task=None, input=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0056c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_indices = batcher.get_mini_batch_indices(mini_batch_size = 10, batch = batch)\n",
    "# mini_batch = batcher.get_mini_batch(index = mini_batch_indices[0], batch = batch)\n",
    "# mini_batch['index'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c781561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of target with class indices\n",
    "loss = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffa2a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn, optimizer):\n",
    "    for mini_batch_num, mini_batch_index in enumerate(mini_batch_indices):\n",
    "        mini_batch = batcher.get_mini_batch(index = mini_batch_indices[mini_batch_num], batch = batch)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(mini_batch)\n",
    "        loss = loss_fn(pred, torch.tensor(mini_batch['label'].values))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 100 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{num_batches:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cf4481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 1\n",
    "optimizer = torch.optim.SGD(assembled_network.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(assembled_network, loss, optimizer)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f89d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = assembled_network(batch)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edc40451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74d5db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import TaskFactory, Conventions\n",
    "from tg.common.ml import dft\n",
    "\n",
    "\n",
    "class MulticlassMetrics(bt.Metric):\n",
    "    def __init__(self, add_accuracy=True, add_rating=False):\n",
    "        self.add_accuracy = add_accuracy\n",
    "        self.add_rating = add_rating\n",
    "\n",
    "    def get_names(self):\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append('accuracy')\n",
    "        if self.add_rating:\n",
    "            result.append('rating')\n",
    "        return result\n",
    "\n",
    "    def measure(self, df, _):\n",
    "        prefix = 'true_label_'\n",
    "        labels = []\n",
    "        for c in df.columns:\n",
    "            if c.startswith(prefix):\n",
    "                labels.append(c.replace(prefix, ''))\n",
    "\n",
    "        def ustack(df, prefix, cols, name):\n",
    "            df = df[[prefix+c for c in cols]]\n",
    "            df.columns = [c for c in cols]\n",
    "            df = df.unstack().to_frame(name)\n",
    "            return df\n",
    "\n",
    "        predicted = ustack(df, 'predicted_label_', labels, 'predicted')\n",
    "        true = ustack(df, 'true_label_', labels, 'true')\n",
    "        df = predicted.merge(true, left_index=True,\n",
    "                             right_index=True).reset_index()\n",
    "        df.columns = ['label', 'sample', 'predicted', 'true']\n",
    "        df = df.feed(fluq.add_ordering_column(\n",
    "            'sample', ('predicted', False), 'predicted_rating'))\n",
    "\n",
    "        match = (df.loc[df.predicted_rating ==\n",
    "                 0].set_index('sample').true > 0.5)\n",
    "        rating = df.loc[df.true > 0.5].set_index('sample').predicted_rating\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append(match.mean())\n",
    "        if self.add_rating:\n",
    "            result.append(rating.mean())\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ae774",
   "metadata": {},
   "source": [
    "TODO: запустить сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef503441",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
