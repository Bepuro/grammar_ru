{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нарушение согласования"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предыдущая попытка в задаче согласования рода - предсказывать род и сравнивать с ответом pymorphy\n",
    "\n",
    "Недостаток - большое количество ошибочных предсказаний в словах, таких как \"морской\". \n",
    "Морской порт и цвет морской волны. Род различается, написание - нет.\n",
    "\n",
    "Попробуем другой подход - предсказание окончаний."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с поиска ошибки согласования прилагательных\n",
    "\n",
    "3 типа:\n",
    "* новЫЙ\n",
    "* хорошИЙ\n",
    "* большОЙ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Построим бандл, сбалансированный по длине предложения и по корпусу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.common import Loc\n",
    "from tg.grammar_ru.corpus import CorpusReader, CorpusBuilder, BucketCorpusBalancer\n",
    "from tg.grammar_ru.corpus.corpus_reader import read_data\n",
    "\n",
    "from yo_fluq_ds import Queryable, Query, fluq\n",
    "\n",
    "from typing import List, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_NAMES = [\n",
    "    \"books.base.zip\", \n",
    "    \"pub.base.zip\"\n",
    "]\n",
    "#TODO: add smth else?\n",
    "\n",
    "CORPUS_LIST = [Loc.corpus_path/corpus_name for corpus_name in CORPUS_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/serhio/Data/1Education/grammar-spring/s2/grammar_ru/data-cache/corpus/books.base.zip'),\n",
       " PosixPath('/home/serhio/Data/1Education/grammar-spring/s2/grammar_ru/data-cache/corpus/pub.base.zip')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_count(corpus_path):\n",
    "    return sum([\n",
    "        len(frame.groupby(\"sentence_id\")) \n",
    "        for frame in read_data(corpus_path)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12481/3628676302.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) read_data. (Use CorpusReader.read_frames_from_several_corpora)\n",
      "  for frame in read_data(corpus_path)\n",
      "100%|██████████| 2533/2533 [00:29<00:00, 84.56it/s] \n",
      "/tmp/ipykernel_12481/3628676302.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) read_data. (Use CorpusReader.read_frames_from_several_corpora)\n",
      "  for frame in read_data(corpus_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books.base.zip = 903668 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66883/66883 [08:15<00:00, 135.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub.base.zip = 1472084 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, corpus_name in enumerate(CORPUS_NAMES):\n",
    "    print(f\"{corpus_name} = {get_sentences_count(CORPUS_LIST[i])} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_BASE = math.e\n",
    "BUCKET_PATH = Loc.corpus_path/\"prepare/buckets/buckets.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69416/69416 [39:07<00:00, 29.57it/s]  \n"
     ]
    }
   ],
   "source": [
    "BucketCorpusBalancer.build_buckets_frame(CORPUS_LIST, BUCKET_PATH, LOG_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>bucket_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>books.base.zip/0</th>\n",
       "      <td>[2105037, 2635119, 2635122, 2930082, 2930089, ...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books.base.zip/1</th>\n",
       "      <td>[7, 8, 11, 15, 10711, 10730, 10731, 10745, 107...</td>\n",
       "      <td>90591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books.base.zip/2</th>\n",
       "      <td>[1, 2, 6, 9, 12, 14, 16, 17, 18, 19, 20, 21, 2...</td>\n",
       "      <td>434207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books.base.zip/3</th>\n",
       "      <td>[0, 3, 4, 5, 10, 13, 10712, 10716, 10718, 1072...</td>\n",
       "      <td>355499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books.base.zip/4</th>\n",
       "      <td>[10715, 10717, 10724, 10744, 10777, 10793, 107...</td>\n",
       "      <td>23177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books.base.zip/5</th>\n",
       "      <td>[189579, 784022, 2391783, 5783820, 5998276, 67...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/0</th>\n",
       "      <td>[51423, 71661, 461963, 1207024, 1404782, 25887...</td>\n",
       "      <td>18308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/1</th>\n",
       "      <td>[24, 33, 34, 40, 52, 53, 64, 11030, 31091, 311...</td>\n",
       "      <td>60391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/2</th>\n",
       "      <td>[3, 5, 6, 8, 10, 14, 18, 21, 25, 26, 28, 30, 3...</td>\n",
       "      <td>415067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/3</th>\n",
       "      <td>[0, 1, 2, 4, 7, 9, 11, 13, 15, 16, 17, 19, 20,...</td>\n",
       "      <td>820561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/4</th>\n",
       "      <td>[12, 31092, 132279, 132283, 132285, 132289, 13...</td>\n",
       "      <td>156624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/5</th>\n",
       "      <td>[875326, 2421677, 3109534, 4275054, 4523347, 5...</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/6</th>\n",
       "      <td>[104900599, 342782477, 649801710, 654923153, 6...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          sentences  \\\n",
       "bucket                                                                \n",
       "books.base.zip/0  [2105037, 2635119, 2635122, 2930082, 2930089, ...   \n",
       "books.base.zip/1  [7, 8, 11, 15, 10711, 10730, 10731, 10745, 107...   \n",
       "books.base.zip/2  [1, 2, 6, 9, 12, 14, 16, 17, 18, 19, 20, 21, 2...   \n",
       "books.base.zip/3  [0, 3, 4, 5, 10, 13, 10712, 10716, 10718, 1072...   \n",
       "books.base.zip/4  [10715, 10717, 10724, 10744, 10777, 10793, 107...   \n",
       "books.base.zip/5  [189579, 784022, 2391783, 5783820, 5998276, 67...   \n",
       "pub.base.zip/0    [51423, 71661, 461963, 1207024, 1404782, 25887...   \n",
       "pub.base.zip/1    [24, 33, 34, 40, 52, 53, 64, 11030, 31091, 311...   \n",
       "pub.base.zip/2    [3, 5, 6, 8, 10, 14, 18, 21, 25, 26, 28, 30, 3...   \n",
       "pub.base.zip/3    [0, 1, 2, 4, 7, 9, 11, 13, 15, 16, 17, 19, 20,...   \n",
       "pub.base.zip/4    [12, 31092, 132279, 132283, 132285, 132289, 13...   \n",
       "pub.base.zip/5    [875326, 2421677, 3109534, 4275054, 4523347, 5...   \n",
       "pub.base.zip/6    [104900599, 342782477, 649801710, 654923153, 6...   \n",
       "\n",
       "                  bucket_size  \n",
       "bucket                         \n",
       "books.base.zip/0          129  \n",
       "books.base.zip/1        90591  \n",
       "books.base.zip/2       434207  \n",
       "books.base.zip/3       355499  \n",
       "books.base.zip/4        23177  \n",
       "books.base.zip/5           65  \n",
       "pub.base.zip/0          18308  \n",
       "pub.base.zip/1          60391  \n",
       "pub.base.zip/2         415067  \n",
       "pub.base.zip/3         820561  \n",
       "pub.base.zip/4         156624  \n",
       "pub.base.zip/5           1127  \n",
       "pub.base.zip/6              6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(BUCKET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NUMBERS = [1, 2, 3, 4]\n",
    "BUCKET_LIMIT = 60_000 #Note: забили на то что в books.base.zip/4 всего 23К предложений.\n",
    "# некторый дисбаланс все-же остался"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BucketCorpusBalancer.filter_buckets_by_bucket_numbers(BUCKET_PATH, BUCKET_NUMBERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>bucket_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>books.base.zip/1</th>\n",
       "      <td>[7, 8, 11, 15, 10711, 10730, 10731, 10745, 107...</td>\n",
       "      <td>90591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books.base.zip/2</th>\n",
       "      <td>[1, 2, 6, 9, 12, 14, 16, 17, 18, 19, 20, 21, 2...</td>\n",
       "      <td>434207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books.base.zip/3</th>\n",
       "      <td>[0, 3, 4, 5, 10, 13, 10712, 10716, 10718, 1072...</td>\n",
       "      <td>355499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books.base.zip/4</th>\n",
       "      <td>[10715, 10717, 10724, 10744, 10777, 10793, 107...</td>\n",
       "      <td>23177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/1</th>\n",
       "      <td>[24, 33, 34, 40, 52, 53, 64, 11030, 31091, 311...</td>\n",
       "      <td>60391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/2</th>\n",
       "      <td>[3, 5, 6, 8, 10, 14, 18, 21, 25, 26, 28, 30, 3...</td>\n",
       "      <td>415067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/3</th>\n",
       "      <td>[0, 1, 2, 4, 7, 9, 11, 13, 15, 16, 17, 19, 20,...</td>\n",
       "      <td>820561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub.base.zip/4</th>\n",
       "      <td>[12, 31092, 132279, 132283, 132285, 132289, 13...</td>\n",
       "      <td>156624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          sentences  \\\n",
       "books.base.zip/1  [7, 8, 11, 15, 10711, 10730, 10731, 10745, 107...   \n",
       "books.base.zip/2  [1, 2, 6, 9, 12, 14, 16, 17, 18, 19, 20, 21, 2...   \n",
       "books.base.zip/3  [0, 3, 4, 5, 10, 13, 10712, 10716, 10718, 1072...   \n",
       "books.base.zip/4  [10715, 10717, 10724, 10744, 10777, 10793, 107...   \n",
       "pub.base.zip/1    [24, 33, 34, 40, 52, 53, 64, 11030, 31091, 311...   \n",
       "pub.base.zip/2    [3, 5, 6, 8, 10, 14, 18, 21, 25, 26, 28, 30, 3...   \n",
       "pub.base.zip/3    [0, 1, 2, 4, 7, 9, 11, 13, 15, 16, 17, 19, 20,...   \n",
       "pub.base.zip/4    [12, 31092, 132279, 132283, 132285, 132289, 13...   \n",
       "\n",
       "                  bucket_size  \n",
       "books.base.zip/1        90591  \n",
       "books.base.zip/2       434207  \n",
       "books.base.zip/3       355499  \n",
       "books.base.zip/4        23177  \n",
       "pub.base.zip/1          60391  \n",
       "pub.base.zip/2         415067  \n",
       "pub.base.zip/3         820561  \n",
       "pub.base.zip/4         156624  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(BUCKET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BALANCED_PATH = Loc.corpus_path/\"prepare/balanced/books&pub_60K_balanced.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.common import Logger\n",
    "def balancing() -> None:\n",
    "    balancer = BucketCorpusBalancer(\n",
    "        buckets = pd.read_parquet(BUCKET_PATH), \n",
    "        log_base = LOG_BASE,\n",
    "        bucket_limit = BUCKET_LIMIT,\n",
    "    )\n",
    "\n",
    "    CorpusBuilder.transfuse_corpus(\n",
    "        sources = CORPUS_LIST,\n",
    "        destination = BALANCED_PATH,\n",
    "        selector = balancer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "balancing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12481/1361944034.py:3: DeprecationWarning: Call to deprecated function (or staticmethod) read_data. (Use CorpusReader.read_frames_from_several_corpora)\n",
      "  for frame in read_data(BALANCED_PATH):\n",
      "100%|██████████| 147/147 [00:11<00:00, 12.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'books.base.zip': 203177, 'pub.base.zip': 240000})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "lengths = defaultdict(int)\n",
    "for frame in read_data(BALANCED_PATH):\n",
    "    for corpus_name in CORPUS_NAMES:\n",
    "        lengths[corpus_name] += len(frame[frame.original_corpus_id == corpus_name].groupby(\"sentence_id\"))\n",
    "\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>part_index</th>\n",
       "      <th>token_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>max_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45f6d5b5-3e14-4346-b848-003eed141143</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 20:24:10.177652</td>\n",
       "      <td>0</td>\n",
       "      <td>49971</td>\n",
       "      <td>220227</td>\n",
       "      <td>0</td>\n",
       "      <td>50269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20ddbb6c-2938-454a-8f12-d5114797b9fe</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 20:24:13.361754</td>\n",
       "      <td>1</td>\n",
       "      <td>49976</td>\n",
       "      <td>216755</td>\n",
       "      <td>1</td>\n",
       "      <td>100630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7acf76d8-cfad-4790-a82e-2902263709cd</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 20:24:17.309190</td>\n",
       "      <td>2</td>\n",
       "      <td>49995</td>\n",
       "      <td>208917</td>\n",
       "      <td>2</td>\n",
       "      <td>151076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab966203-6129-4f22-9dac-fa01e965b601</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 20:24:24.177992</td>\n",
       "      <td>3</td>\n",
       "      <td>49987</td>\n",
       "      <td>209376</td>\n",
       "      <td>3</td>\n",
       "      <td>202229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670730b-1f7f-4bf1-808b-33717f778f77</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 20:24:29.437513</td>\n",
       "      <td>4</td>\n",
       "      <td>49966</td>\n",
       "      <td>208659</td>\n",
       "      <td>4</td>\n",
       "      <td>253031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>062f6711-5af1-4fa5-8ccf-5bf2d4a95bff</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 21:48:25.985407</td>\n",
       "      <td>142</td>\n",
       "      <td>49992</td>\n",
       "      <td>252939</td>\n",
       "      <td>142</td>\n",
       "      <td>7763628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612d244c-ae4d-4b4c-9076-e9723c63259e</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 21:49:10.772981</td>\n",
       "      <td>143</td>\n",
       "      <td>49984</td>\n",
       "      <td>253894</td>\n",
       "      <td>143</td>\n",
       "      <td>7818826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0bd18961-2d09-4e6c-ba2d-8786f6de8627</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 21:49:58.524944</td>\n",
       "      <td>144</td>\n",
       "      <td>49985</td>\n",
       "      <td>255516</td>\n",
       "      <td>144</td>\n",
       "      <td>7874300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9bf01be0-2659-48f9-af10-661c796e5ca3</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 21:50:42.913805</td>\n",
       "      <td>145</td>\n",
       "      <td>49997</td>\n",
       "      <td>253088</td>\n",
       "      <td>145</td>\n",
       "      <td>7929412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2f3c532-4efa-43c5-940b-12b2c36bc445</th>\n",
       "      <td></td>\n",
       "      <td>2023-03-13 21:51:19.388726</td>\n",
       "      <td>146</td>\n",
       "      <td>37957</td>\n",
       "      <td>192046</td>\n",
       "      <td>146</td>\n",
       "      <td>7971637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename                  timestamp  \\\n",
       "file_id                                                                    \n",
       "45f6d5b5-3e14-4346-b848-003eed141143          2023-03-13 20:24:10.177652   \n",
       "20ddbb6c-2938-454a-8f12-d5114797b9fe          2023-03-13 20:24:13.361754   \n",
       "7acf76d8-cfad-4790-a82e-2902263709cd          2023-03-13 20:24:17.309190   \n",
       "ab966203-6129-4f22-9dac-fa01e965b601          2023-03-13 20:24:24.177992   \n",
       "3670730b-1f7f-4bf1-808b-33717f778f77          2023-03-13 20:24:29.437513   \n",
       "...                                       ...                        ...   \n",
       "062f6711-5af1-4fa5-8ccf-5bf2d4a95bff          2023-03-13 21:48:25.985407   \n",
       "612d244c-ae4d-4b4c-9076-e9723c63259e          2023-03-13 21:49:10.772981   \n",
       "0bd18961-2d09-4e6c-ba2d-8786f6de8627          2023-03-13 21:49:58.524944   \n",
       "9bf01be0-2659-48f9-af10-661c796e5ca3          2023-03-13 21:50:42.913805   \n",
       "c2f3c532-4efa-43c5-940b-12b2c36bc445          2023-03-13 21:51:19.388726   \n",
       "\n",
       "                                      part_index  token_count  \\\n",
       "file_id                                                         \n",
       "45f6d5b5-3e14-4346-b848-003eed141143           0        49971   \n",
       "20ddbb6c-2938-454a-8f12-d5114797b9fe           1        49976   \n",
       "7acf76d8-cfad-4790-a82e-2902263709cd           2        49995   \n",
       "ab966203-6129-4f22-9dac-fa01e965b601           3        49987   \n",
       "3670730b-1f7f-4bf1-808b-33717f778f77           4        49966   \n",
       "...                                          ...          ...   \n",
       "062f6711-5af1-4fa5-8ccf-5bf2d4a95bff         142        49992   \n",
       "612d244c-ae4d-4b4c-9076-e9723c63259e         143        49984   \n",
       "0bd18961-2d09-4e6c-ba2d-8786f6de8627         144        49985   \n",
       "9bf01be0-2659-48f9-af10-661c796e5ca3         145        49997   \n",
       "c2f3c532-4efa-43c5-940b-12b2c36bc445         146        37957   \n",
       "\n",
       "                                      character_count  ordinal   max_id  \n",
       "file_id                                                                  \n",
       "45f6d5b5-3e14-4346-b848-003eed141143           220227        0    50269  \n",
       "20ddbb6c-2938-454a-8f12-d5114797b9fe           216755        1   100630  \n",
       "7acf76d8-cfad-4790-a82e-2902263709cd           208917        2   151076  \n",
       "ab966203-6129-4f22-9dac-fa01e965b601           209376        3   202229  \n",
       "3670730b-1f7f-4bf1-808b-33717f778f77           208659        4   253031  \n",
       "...                                               ...      ...      ...  \n",
       "062f6711-5af1-4fa5-8ccf-5bf2d4a95bff           252939      142  7763628  \n",
       "612d244c-ae4d-4b4c-9076-e9723c63259e           253894      143  7818826  \n",
       "0bd18961-2d09-4e6c-ba2d-8786f6de8627           255516      144  7874300  \n",
       "9bf01be0-2659-48f9-af10-661c796e5ca3           253088      145  7929412  \n",
       "c2f3c532-4efa-43c5-940b-12b2c36bc445           192046      146  7971637  \n",
       "\n",
       "[147 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.grammar_ru import CorpusReader\n",
    "from tg.grammar_ru.corpus import CorpusBuilder\n",
    "from pathlib import Path\n",
    "\n",
    "# corpus = Path('files/corpus.zip')\n",
    "reader = CorpusReader(BALANCED_PATH)\n",
    "reader.get_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Собственно\n",
       "1        потому\n",
       "2             ,\n",
       "3           что\n",
       "4       перевод\n",
       "5            от\n",
       "6        РОСМЭН\n",
       "7           был\n",
       "8         очень\n",
       "9          плох\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.read_frames().first().word.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reader.read_frames().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: we need nltk in requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tg.common import DataBundle\n",
    "from tg.common.ml.batched_training import train_display_test_split\n",
    "from tg.grammar_ru.features import PyMorphyFeaturizer\n",
    "\n",
    "from tg.grammar_ru.corpus import ITransfuseSelector\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "class AdjAgreementTrainIndexBuilder(ITransfuseSelector):\n",
    "    def __init__(self):\n",
    "        self.pmf = PyMorphyFeaturizer()\n",
    "        self.snowball = SnowballStemmer(language=\"russian\")\n",
    "        # self.speech_part_labels = [\n",
    "        #     'ADJF', 'ADJS', 'VERB', 'PRTF', 'PRTS']\n",
    "        # self.gender_nums = {g: i for i, g in enumerate(\n",
    "        #     ['masc', 'femn', 'neut'])}  # , 'nan'])}\n",
    "\n",
    "    # def get_ending(normal_form)\n",
    "    def select(self, source, df, toc_row):  # ~build_train_index\n",
    "        df['label'] = -1\n",
    "        db = DataBundle(src=df)\n",
    "        self.pmf.featurize(db)  # запишет результат по ключу pymorphy\n",
    "        morphed = db.data_frames['pymorphy']\n",
    "        morphed.replace({np.nan: 'nan'}, inplace=True)\n",
    "        return morphed\n",
    "        a = morphed.POS.isin(self.speech_part_labels)\n",
    "        b = (~df.word.str[0].str.isupper())\n",
    "        g = morphed.gender\n",
    "        c = (g != 'nan')\n",
    "        df['is_target'] = a & b & c\n",
    "        gender_scores_cols = [\n",
    "            'gender_masc_score', 'gender_femn_score', 'gender_neut_score', 'gender_None_score']\n",
    "        # 'gender_masc_score', 'gender_femn_score', 'gender_neut_score', 'gender_None_score'\n",
    "        df[gender_scores_cols] = morphed[gender_scores_cols]\n",
    "        df.loc[df.is_target, 'label'] = morphed[df.is_target].gender.replace(\n",
    "            self.gender_nums)\n",
    "        return [df]\n",
    "\n",
    "    @staticmethod\n",
    "    def build_index_from_src(src_df):\n",
    "        df = src_df.loc[src_df.is_target][[\n",
    "            'word_id', 'sentence_id', 'label']].copy()\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.index.name = 'sample_id'\n",
    "        df['split'] = train_display_test_split(df)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_builder = AdjAgreementTrainIndexBuilder()\n",
    "m = index_builder.select(_, df, _)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(language=\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ending(normal_form):\n",
    "    return snowball.stem(normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives = m[m.POS =='ADJF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9771/4025221798.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adjectives[\"end\"] = adjectives.normal_form.apply(get_ending)\n"
     ]
    }
   ],
   "source": [
    "adjectives[\"end\"] = adjectives.normal_form.apply(get_ending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_form</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>тот</td>\n",
       "      <td>тот</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>сам</td>\n",
       "      <td>сам</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>который</td>\n",
       "      <td>котор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>тихий</td>\n",
       "      <td>тих</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>говорящий</td>\n",
       "      <td>говоря</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>который</td>\n",
       "      <td>котор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>сей</td>\n",
       "      <td>се</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>волшебный</td>\n",
       "      <td>волшебн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>немагический</td>\n",
       "      <td>немагическ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>кой</td>\n",
       "      <td>ко</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>трудный</td>\n",
       "      <td>трудн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>самый</td>\n",
       "      <td>сам</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>разнообразный</td>\n",
       "      <td>разнообразн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>этот</td>\n",
       "      <td>этот</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>тот</td>\n",
       "      <td>тот</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>наш</td>\n",
       "      <td>наш</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>серьёзный</td>\n",
       "      <td>серьезн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>такой</td>\n",
       "      <td>так</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>немагический</td>\n",
       "      <td>немагическ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>ваш</td>\n",
       "      <td>ваш</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>последний</td>\n",
       "      <td>последн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>отчаянный</td>\n",
       "      <td>отчая</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>один</td>\n",
       "      <td>один</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>живой</td>\n",
       "      <td>жив</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>этот</td>\n",
       "      <td>этот</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>тщетный</td>\n",
       "      <td>тщетн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>любой</td>\n",
       "      <td>люб</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>этот</td>\n",
       "      <td>этот</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>неприятный</td>\n",
       "      <td>неприятн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>который</td>\n",
       "      <td>котор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>полный</td>\n",
       "      <td>полн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>свой</td>\n",
       "      <td>сво</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>личный</td>\n",
       "      <td>личн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>безобразный</td>\n",
       "      <td>безобразн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>один</td>\n",
       "      <td>один</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>тот</td>\n",
       "      <td>тот</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>грязновато-коричневый</td>\n",
       "      <td>грязновато-коричнев</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>пустой</td>\n",
       "      <td>пуст</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>похожий</td>\n",
       "      <td>похож</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>один</td>\n",
       "      <td>один</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>который</td>\n",
       "      <td>котор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>полный</td>\n",
       "      <td>полн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>аксминстерский</td>\n",
       "      <td>аксминстерск</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>дикий</td>\n",
       "      <td>дик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>который</td>\n",
       "      <td>котор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>свой</td>\n",
       "      <td>сво</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>серый</td>\n",
       "      <td>сер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>какой-то</td>\n",
       "      <td>какой-т</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>неведомый</td>\n",
       "      <td>неведом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>свой</td>\n",
       "      <td>сво</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   normal_form                  end\n",
       "word_id                                            \n",
       "500                        тот                  тот\n",
       "502                        сам                  сам\n",
       "509                    который                котор\n",
       "519                      тихий                  тих\n",
       "529                  говорящий               говоря\n",
       "545                    который                котор\n",
       "579                        сей                   се\n",
       "607                  волшебный              волшебн\n",
       "614               немагический           немагическ\n",
       "618                        кой                   ко\n",
       "632                    трудный                трудн\n",
       "636                      самый                  сам\n",
       "637              разнообразный          разнообразн\n",
       "657                       этот                 этот\n",
       "683                        тот                  тот\n",
       "688                        наш                  наш\n",
       "693                  серьёзный              серьезн\n",
       "696                      такой                  так\n",
       "709               немагический           немагическ\n",
       "724                        ваш                  ваш\n",
       "730                  последний              последн\n",
       "732                  отчаянный                отчая\n",
       "761                       один                 один\n",
       "762                      живой                  жив\n",
       "770                       этот                 этот\n",
       "782                    тщетный                тщетн\n",
       "786                      любой                  люб\n",
       "789                       этот                 этот\n",
       "790                 неприятный             неприятн\n",
       "797                    который                котор\n",
       "802                     полный                 полн\n",
       "808                       свой                  сво\n",
       "809                     личный                 личн\n",
       "815                безобразный            безобразн\n",
       "843                       один                 один\n",
       "847                        тот                  тот\n",
       "854      грязновато-коричневый  грязновато-коричнев\n",
       "857                     пустой                 пуст\n",
       "890                    похожий                похож\n",
       "896                       один                 один\n",
       "909                    который                котор\n",
       "922                     полный                 полн\n",
       "935             аксминстерский         аксминстерск\n",
       "941                      дикий                  дик\n",
       "947                    который                котор\n",
       "951                       свой                  сво\n",
       "959                      серый                  сер\n",
       "964                   какой-то              какой-т\n",
       "965                  неведомый              неведом\n",
       "990                       свой                  сво"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives[['normal_form','end']][50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='хорошего', tag=OpencorporaTag('ADJF,Qual neut,sing,gent'), normal_form='хороший', score=0.833333, methods_stack=((DictionaryAnalyzer(), 'хорошего', 3135, 15),)),\n",
       " Parse(word='хорошего', tag=OpencorporaTag('ADJF,Qual masc,sing,gent'), normal_form='хороший', score=0.111111, methods_stack=((DictionaryAnalyzer(), 'хорошего', 3135, 1),)),\n",
       " Parse(word='хорошего', tag=OpencorporaTag('ADJF,Qual anim,masc,sing,accs'), normal_form='хороший', score=0.055555, methods_stack=((DictionaryAnalyzer(), 'хорошего', 3135, 3),))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse(\"хорошего\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7225.15s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 KB\u001b[0m \u001b[31m738.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/serhio/Data/1Education/grammar-spring/s2/grammar_ru/env/lib/python3.10/site-packages (from requests->pymystem3) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/serhio/Data/1Education/grammar-spring/s2/grammar_ru/env/lib/python3.10/site-packages (from requests->pymystem3) (1.26.14)\n",
      "Installing collected packages: charset-normalizer, certifi, requests, pymystem3\n",
      "Successfully installed certifi-2022.12.7 charset-normalizer-3.1.0 pymystem3-0.2.0 requests-2.28.2\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /home/serhio/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['красивый', ' ', 'мама', ' ', 'красиво', ' ', 'мыть', ' ', 'рама', '\\n']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Mystem()\n",
    "m.lemmatize(\"Красивая мама красиво мыла раму\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"analysis\": [{\"lex\": \"красивый\", \"wt\": 1, \"gr\": \"A=им,ед,полн,жен\"}], \"text\": \"Красивая\"}, {\"text\": \" \"}, {\"analysis\": [{\"lex\": \"мама\", \"wt\": 1, \"gr\": \"S,жен,од=им,ед\"}], \"text\": \"мама\"}, {\"text\": \" \"}, {\"analysis\": [{\"lex\": \"красиво\", \"wt\": 0.8149252476, \"gr\": \"ADV=\"}], \"text\": \"красиво\"}, {\"text\": \" \"}, {\"analysis\": [{\"lex\": \"мыть\", \"wt\": 0.441520999, \"gr\": \"V,несов,пе=прош,ед,изъяв,жен\"}], \"text\": \"мыла\"}, {\"text\": \" \"}, {\"analysis\": [{\"lex\": \"рама\", \"wt\": 0.9993591156, \"gr\": \"S,жен,неод=вин,ед\"}], \"text\": \"раму\"}, {\"text\": \"\\\\n\"}]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Красивая мама красиво мыла раму'\n",
    "import json\n",
    "json.dumps(m.analyze(text), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m.analyze('мама сделала так, как сказал ваш начальник')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мама S\n",
      "сделала V\n",
      "деревянную A\n",
      "шкатулку S\n",
      "так ADVPRO\n",
      "как ADVPRO\n",
      "сказал V\n",
      "первый ANUM\n",
      "начальник S\n"
     ]
    }
   ],
   "source": [
    "for word_info in m.analyze('мама сделала деревянную шкатулку так, как сказал первый начальник'):\n",
    "    if 'analysis' not in word_info:\n",
    "        continue\n",
    "    # print(word_info[\"analysis\"][0][\"gr\"].split(',')[0])\n",
    "    print(word_info['text'], re.split(',|=', word_info[\"analysis\"][0][\"gr\"])[0])\n",
    "    # print()#.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.analyze('мама сделала так, как сказал ваш начальник')[0][\"analysis\"][0][\"gr\"].split(',')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'морской',\n",
       "    'wt': 1,\n",
       "    'gr': 'A,полн=(пр,ед,жен|дат,ед,жен|род,ед,жен|твор,ед,жен|вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'морской'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.analyze('морской')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
