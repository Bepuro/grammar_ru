{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tg.grammar_ru.common import Loc\n",
    "\n",
    "import re\n",
    "\n",
    "from tg.common import DataBundle\n",
    "from tg.common.ml.batched_training import train_display_test_split\n",
    "from tg.grammar_ru.features import PyMorphyFeaturizer\n",
    "\n",
    "from tg.grammar_ru.corpus import ITransfuseSelector\n",
    "from nltk.stem import SnowballStemmer\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "# mystem = Mystem()\n",
    "\n",
    "new = {'ая', 'ого', 'ое', 'ой', 'ом', 'ому',\n",
    "       'ою', 'ую', 'ые', 'ый', 'ым', 'ыми', 'ых'}\n",
    "\n",
    "good = {'ая', 'его', 'ее', 'ей', 'ем', 'ему',\n",
    "        'ие', 'ий', 'им', 'ими', 'их', 'ую', 'яя', 'юю'}\n",
    "\n",
    "big = {'ая', 'ие', 'им', 'ими', 'их', 'ого',\n",
    "       'ое', 'ой', 'ом', 'ому', 'ою', 'ую'}\n",
    "\n",
    "POSSIBLE_ENDINGS = set().union(new, good, big)\n",
    "\n",
    "\n",
    "# def _get_poses_by_sentence(sentence: str):\n",
    "#     # NOTE: краткие прилагательные mystem'ом отмечаются как прилагательные. e.g. Хороша, плох.\n",
    "#     res = []\n",
    "#     for word_info in mystem.analyze(sentence):\n",
    "#         if 'analysis' not in word_info or not word_info[\"analysis\"]:\n",
    "#             continue\n",
    "#         res.append(\n",
    "#             (word_info[\"text\"],\n",
    "#              re.split(\n",
    "#                  ',|=', word_info[\"analysis\"][0][\"gr\"])[0])\n",
    "#         )\n",
    "#     return res\n",
    "\n",
    "\n",
    "# def _set_mystem_pos(df):\n",
    "#     df['pos_mystem'] = np.nan\n",
    "#     for sent_id, tokens_group in df.groupby(\"sentence_id\"):\n",
    "#         sentence = ' '.join(tokens_group.word)\n",
    "#         poses = _get_poses_by_sentence(sentence)\n",
    "#         if not poses:\n",
    "#             continue\n",
    "#         j = 0\n",
    "#         for i in tokens_group.index:  # zip with gaps\n",
    "#             word, pos = poses[j]\n",
    "#             if df.at[i, 'word'] == word:\n",
    "#                 df.at[i, 'pos_mystem'] = pos\n",
    "#                 j += 1\n",
    "#                 if j == len(poses):\n",
    "#                     break\n",
    "\n",
    "\n",
    "def _extract_ending(word: str):\n",
    "    for possible_ending in POSSIBLE_ENDINGS:  # TODO can we make it faster?\n",
    "        if word.lower().endswith(possible_ending):\n",
    "            return possible_ending\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "class AdjAgreementTrainIndexBuilder(ITransfuseSelector):\n",
    "    def __init__(self):\n",
    "        self.pmf = PyMorphyFeaturizer()\n",
    "        self.snowball = SnowballStemmer(language=\"russian\")\n",
    "        self.norm_endings_nums = {e: i for i,\n",
    "                                  e in enumerate(['ый', 'ий', 'ой'])}\n",
    "        self.endings_nums = {e: i for i, e in enumerate(\n",
    "            sorted(list(POSSIBLE_ENDINGS)))}\n",
    "\n",
    "    def _extract_norm_ending(self, word_in_norm_form: str):\n",
    "        for possible_ending in self.norm_endings_nums.keys():\n",
    "            if word_in_norm_form.lower().endswith(possible_ending):\n",
    "                return possible_ending\n",
    "        return np.nan\n",
    "\n",
    "    def select(self, source, df, toc_row):  # ~build_train_index\n",
    "        # _set_mystem_pos(df)\n",
    "        db = DataBundle(src=df)\n",
    "        self.pmf.featurize(db)  # запишет результат по ключу pymorphy\n",
    "        morphed = db.data_frames['pymorphy']\n",
    "        morphed.replace({np.nan: 'nan'}, inplace=True)\n",
    "        adjectives = df[\n",
    "            # (df.pos_mystem == 'A') &\n",
    "            (morphed.POS == \"ADJF\")\n",
    "        ].copy()  # TODO delete\n",
    "        df['is_target'] = False\n",
    "        df['declension_type'] = -1\n",
    "\n",
    "        adjectives['ending'] = (adjectives.word\n",
    "                                .apply(_extract_ending))\n",
    "\n",
    "        morphed_adjectives = morphed.loc[adjectives.index]\n",
    "        adjectives['norm_ending'] = (morphed_adjectives.normal_form\n",
    "                                     .apply(self._extract_norm_ending))\n",
    "\n",
    "        # adjectives['norm_form'] = morphed_adjectives.normal_form\n",
    "        undefined_ending_mask = (adjectives.norm_ending.isnull() |\n",
    "                                 adjectives.ending.isnull())\n",
    "        with open(Loc.temp_path / \"undefined_ending.txt\", \"a\") as myfile:\n",
    "            for w in adjectives[undefined_ending_mask].word:\n",
    "                myfile.write(f'{w}\\n')\n",
    "        adjectives = adjectives[~undefined_ending_mask]\n",
    "        # NOTE: отбросили слова, у которых не смогли определить окончание. e.g. волчий\n",
    "        df.loc[adjectives.index, 'declension_type'] = adjectives.norm_ending.replace(\n",
    "            self.norm_endings_nums)\n",
    "        df.declension_type = df.declension_type.astype(int)\n",
    "        df['label'] = -1\n",
    "        df.loc[adjectives.index, 'label'] = adjectives.ending.replace(\n",
    "            self.endings_nums)\n",
    "        df.loc[adjectives.index, 'is_target'] = True\n",
    "        return [df]\n",
    "\n",
    "    @staticmethod\n",
    "    def build_index_from_src(src_df):\n",
    "        df = src_df.loc[src_df.is_target][[\n",
    "            'word_id', 'sentence_id', 'label']].copy()\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.index.name = 'sample_id'\n",
    "        df['split'] = train_display_test_split(df)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru import CorpusReader\n",
    "\n",
    "builder = AdjAgreementTrainIndexBuilder()\n",
    "\n",
    "reader = CorpusReader(Loc.corpus_path / 'prepare/balanced/books&pub_60K_balanced_feat.zip')\n",
    "df = reader.get_frames().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>original_corpus_id</th>\n",
       "      <th>original_word_id</th>\n",
       "      <th>original_sentence_id</th>\n",
       "      <th>original_paragraph_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>is_target</th>\n",
       "      <th>declension_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>другие</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>русскоязычные</td>\n",
       "      <td>ru</td>\n",
       "      <td>13</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Приятного</td>\n",
       "      <td>ru</td>\n",
       "      <td>9</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>122</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>злосчастный</td>\n",
       "      <td>ru</td>\n",
       "      <td>11</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>10754</td>\n",
       "      <td>10715</td>\n",
       "      <td>10711</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>78</td>\n",
       "      <td>16</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>неприятных</td>\n",
       "      <td>ru</td>\n",
       "      <td>10</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>10762</td>\n",
       "      <td>10715</td>\n",
       "      <td>10711</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50162</th>\n",
       "      <td>50162</td>\n",
       "      <td>49522</td>\n",
       "      <td>21</td>\n",
       "      <td>49517</td>\n",
       "      <td>1</td>\n",
       "      <td>чужие</td>\n",
       "      <td>ru</td>\n",
       "      <td>5</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>445672</td>\n",
       "      <td>443264</td>\n",
       "      <td>443170</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50183</th>\n",
       "      <td>50183</td>\n",
       "      <td>49523</td>\n",
       "      <td>2</td>\n",
       "      <td>49518</td>\n",
       "      <td>1</td>\n",
       "      <td>двойной</td>\n",
       "      <td>ru</td>\n",
       "      <td>7</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>445813</td>\n",
       "      <td>443274</td>\n",
       "      <td>443178</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50186</th>\n",
       "      <td>50186</td>\n",
       "      <td>49523</td>\n",
       "      <td>5</td>\n",
       "      <td>49518</td>\n",
       "      <td>1</td>\n",
       "      <td>старый</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>445816</td>\n",
       "      <td>443274</td>\n",
       "      <td>443178</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50240</th>\n",
       "      <td>50240</td>\n",
       "      <td>49525</td>\n",
       "      <td>25</td>\n",
       "      <td>49519</td>\n",
       "      <td>1</td>\n",
       "      <td>Темного</td>\n",
       "      <td>ru</td>\n",
       "      <td>7</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>445928</td>\n",
       "      <td>443280</td>\n",
       "      <td>443180</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50260</th>\n",
       "      <td>50260</td>\n",
       "      <td>49527</td>\n",
       "      <td>15</td>\n",
       "      <td>49521</td>\n",
       "      <td>1</td>\n",
       "      <td>который</td>\n",
       "      <td>ru</td>\n",
       "      <td>7</td>\n",
       "      <td>45f6d5b5-3e14-4346-b848-003eed141143</td>\n",
       "      <td>books&amp;pub_60K_balanced_feat.zip</td>\n",
       "      <td>books.base.zip</td>\n",
       "      <td>446096</td>\n",
       "      <td>443295</td>\n",
       "      <td>443186</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3057 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_id  sentence_id  word_index  paragraph_id  word_tail  \\\n",
       "14          14            0          14             0          1   \n",
       "15          15            0          15             0          1   \n",
       "20          20            1           0             1          1   \n",
       "96          96           78           8            76          1   \n",
       "104        104           78          16            76          1   \n",
       "...        ...          ...         ...           ...        ...   \n",
       "50162    50162        49522          21         49517          1   \n",
       "50183    50183        49523           2         49518          1   \n",
       "50186    50186        49523           5         49518          1   \n",
       "50240    50240        49525          25         49519          1   \n",
       "50260    50260        49527          15         49521          1   \n",
       "\n",
       "                word word_type  word_length  \\\n",
       "14            другие        ru            6   \n",
       "15     русскоязычные        ru           13   \n",
       "20         Приятного        ru            9   \n",
       "96       злосчастный        ru           11   \n",
       "104       неприятных        ru           10   \n",
       "...              ...       ...          ...   \n",
       "50162          чужие        ru            5   \n",
       "50183        двойной        ru            7   \n",
       "50186         старый        ru            6   \n",
       "50240        Темного        ru            7   \n",
       "50260        который        ru            7   \n",
       "\n",
       "                                    file_id                        corpus_id  \\\n",
       "14     45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "15     45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "20     45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "96     45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "104    45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "...                                     ...                              ...   \n",
       "50162  45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "50183  45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "50186  45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "50240  45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "50260  45f6d5b5-3e14-4346-b848-003eed141143  books&pub_60K_balanced_feat.zip   \n",
       "\n",
       "      original_corpus_id  original_word_id  original_sentence_id  \\\n",
       "14        books.base.zip                88                     4   \n",
       "15        books.base.zip                89                     4   \n",
       "20        books.base.zip               122                     7   \n",
       "96        books.base.zip             10754                 10715   \n",
       "104       books.base.zip             10762                 10715   \n",
       "...                  ...               ...                   ...   \n",
       "50162     books.base.zip            445672                443264   \n",
       "50183     books.base.zip            445813                443274   \n",
       "50186     books.base.zip            445816                443274   \n",
       "50240     books.base.zip            445928                443280   \n",
       "50260     books.base.zip            446096                443295   \n",
       "\n",
       "       original_paragraph_id  updated  is_target declension_type  label  \n",
       "14                         1    False       True               2      6  \n",
       "15                         1    False       True               0     18  \n",
       "20                         3    False       True               0     11  \n",
       "96                     10711    False       True               0     19  \n",
       "104                    10711    False       True               0     22  \n",
       "...                      ...      ...        ...             ...    ...  \n",
       "50162                 443170    False       True               2      6  \n",
       "50183                 443178    False       True               2     13  \n",
       "50186                 443178    False       True               0     19  \n",
       "50240                 443180    False       True               0     11  \n",
       "50260                 443186    False       True               0     19  \n",
       "\n",
       "[3057 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = builder.select(_,df,_)[0]\n",
    "# ind[ind.is_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m builder \u001b[39m=\u001b[39m AdjAgreementTrainIndexBuilder()\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m  reader\u001b[39m.\u001b[39mget_frames():\n\u001b[0;32m----> 3\u001b[0m     builder\u001b[39m.\u001b[39;49mselect(_,df,_)\n",
      "Cell \u001b[0;32mIn[1], line 79\u001b[0m, in \u001b[0;36mAdjAgreementTrainIndexBuilder.select\u001b[0;34m(self, source, df, toc_row)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, source, df, toc_row):  \u001b[39m# ~build_train_index\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[39m# _set_mystem_pos(df)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     db \u001b[39m=\u001b[39m DataBundle(src\u001b[39m=\u001b[39mdf)\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpmf\u001b[39m.\u001b[39;49mfeaturize(db)  \u001b[39m# запишет результат по ключу pymorphy\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     morphed \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mdata_frames[\u001b[39m'\u001b[39m\u001b[39mpymorphy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     81\u001b[0m     morphed\u001b[39m.\u001b[39mreplace({np\u001b[39m.\u001b[39mnan: \u001b[39m'\u001b[39m\u001b[39mnan\u001b[39m\u001b[39m'\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Data/1Education/grammar-spring/s2/grammar_ru/tg/grammar_ru/features/architecture.py:57\u001b[0m, in \u001b[0;36mSimpleFeaturizer.featurize\u001b[0;34m(self, db)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeaturize\u001b[39m(\u001b[39mself\u001b[39m, db: DataBundle) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     db[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe_name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_featurize_inner(db)\n",
      "File \u001b[0;32m~/Data/1Education/grammar-spring/s2/grammar_ru/tg/grammar_ru/features/pymorphy_featurizer.py:38\u001b[0m, in \u001b[0;36mPyMorphyFeaturizer._featurize_inner\u001b[0;34m(self, db)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_featurize_inner\u001b[39m(\u001b[39mself\u001b[39m, db: DataBundle):\n\u001b[1;32m     36\u001b[0m     rows \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mfor\u001b[39;00m src_row \u001b[39min\u001b[39;00m Query\u001b[39m.\u001b[39mdf(db\u001b[39m.\u001b[39msrc):\n\u001b[1;32m     39\u001b[0m         \u001b[39mif\u001b[39;00m src_row\u001b[39m.\u001b[39mword \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache:\n\u001b[1;32m     40\u001b[0m             row \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache[src_row\u001b[39m.\u001b[39mword])\n",
      "File \u001b[0;32m~/Data/1Education/grammar-spring/s2/grammar_ru/env/lib/python3.10/site-packages/yo_fluq/_queries/queryable_code_factory.py:13\u001b[0m, in \u001b[0;36mQueryableCodeFactory.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39men:\n\u001b[1;32m     14\u001b[0m         \u001b[39myield\u001b[39;00m e\n",
      "File \u001b[0;32m~/Data/1Education/grammar-spring/s2/grammar_ru/env/lib/python3.10/site-packages/yo_fluq_ds/_queries/query_class.py:13\u001b[0m, in \u001b[0;36m_df_iter\u001b[0;34m(dataframe, as_obj)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m dataframe\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m as_obj:\n\u001b[0;32m---> 13\u001b[0m         \u001b[39myield\u001b[39;00m Obj(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrow[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mto_dict())\n\u001b[1;32m     14\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m         \u001b[39myield\u001b[39;00m row[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/Data/1Education/grammar-spring/s2/grammar_ru/env/lib/python3.10/site-packages/pandas/core/series.py:1895\u001b[0m, in \u001b[0;36mSeries.to_dict\u001b[0;34m(self, into)\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[39m# GH16122\u001b[39;00m\n\u001b[1;32m   1894\u001b[0m into_c \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mstandardize_mapping(into)\n\u001b[0;32m-> 1895\u001b[0m \u001b[39mreturn\u001b[39;00m into_c((k, maybe_box_native(v)) \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m~/Data/1Education/grammar-spring/s2/grammar_ru/env/lib/python3.10/site-packages/pandas/core/series.py:1895\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[39m# GH16122\u001b[39;00m\n\u001b[1;32m   1894\u001b[0m into_c \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mstandardize_mapping(into)\n\u001b[0;32m-> 1895\u001b[0m \u001b[39mreturn\u001b[39;00m into_c((k, maybe_box_native(v)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems())\n",
      "File \u001b[0;32m~/Data/1Education/grammar-spring/s2/grammar_ru/env/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:179\u001b[0m, in \u001b[0;36mmaybe_box_native\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    174\u001b[0m         value \u001b[39m=\u001b[39m Timedelta(value)\n\u001b[1;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m--> 179\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmaybe_box_native\u001b[39m(value: Scalar) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Scalar:\n\u001b[1;32m    180\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m    If passed a scalar cast the scalar to a python native type.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39m    scalar or Series\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m is_float(value):\n\u001b[1;32m    192\u001b[0m         \u001b[39m# error: Argument 1 to \"float\" has incompatible type\u001b[39;00m\n\u001b[1;32m    193\u001b[0m         \u001b[39m# \"Union[Union[str, int, float, bool], Union[Any, Timestamp, Timedelta, Any]]\";\u001b[39;00m\n\u001b[1;32m    194\u001b[0m         \u001b[39m# expected \"Union[SupportsFloat, _SupportsIndex, str]\"\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for df in  reader.get_frames():\n",
    "    builder.select(_,df,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
