{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tg.grammar_ru.common import Loc\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "\n",
    "from tg.common import DataBundle\n",
    "from tg.common.ml.batched_training import train_display_test_split\n",
    "from tg.grammar_ru.features import PyMorphyFeaturizer\n",
    "\n",
    "from tg.grammar_ru.corpus import ITransfuseSelector\n",
    "from nltk.stem import SnowballStemmer\n",
    "from tg.projects.agreement.bundles_tools import _print_thrown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дядей, землёй Note в печатных текстах, наверное, ё заменяют на е\n",
    "first_declension_ends = set(\"а я ы и е у ю ой ёй ей \".split())\n",
    "# second_declension_ends = set(\"а я ы и е у ю ой ёй ей ою \".split())\n",
    "POSSIBLE_ENDINGS = first_declension_ends\n",
    "\n",
    "ends_list = sorted(list(first_declension_ends))\n",
    "num_by_end = {e: n for n, e in enumerate(ends_list)}\n",
    "\n",
    "\n",
    "def _extract_ending(word: str):\n",
    "    for possible_ending in POSSIBLE_ENDINGS:\n",
    "        if word.lower().endswith(possible_ending):\n",
    "            return possible_ending\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "class NounAgreementTrainIndexBuilder(ITransfuseSelector):\n",
    "    def __init__(self):\n",
    "        self.pmf = PyMorphyFeaturizer()\n",
    "        # self.snowball = SnowballStemmer(language=\"russian\")\n",
    "        self.norm_endings_nums = {e: i for i,\n",
    "                                  e in enumerate(['я', 'а'])}\n",
    "        # self.endings_nums = {e: i for i, e in enumerate(ALL_ENDS_list)}\n",
    "\n",
    "    def _extract_norm_ending(self, word_in_norm_form: str):\n",
    "        for possible_ending in self.norm_endings_nums.keys():\n",
    "            if word_in_norm_form.lower().endswith(possible_ending):\n",
    "                return possible_ending\n",
    "        return np.nan\n",
    "\n",
    "    def select(self, source, df, toc_row):\n",
    "        db = DataBundle(src=df)\n",
    "        self.pmf.featurize(db)\n",
    "        morphed = db.data_frames['pymorphy']\n",
    "        morphed.replace({np.nan: 'nan'}, inplace=True)\n",
    "        nouns = df[(morphed.POS == \"NOUN\")].copy()  # TODO delete\n",
    "        # return morphed[(morphed.POS == \"NOUN\")]\n",
    "        df['is_target'] = False\n",
    "        df['declension_type'] = -1\n",
    "\n",
    "        nouns['ending'] = (nouns.word\n",
    "                           .apply(_extract_ending))\n",
    "\n",
    "        morphed_nouns = morphed.loc[nouns.index]\n",
    "        nouns['norm_ending'] = (morphed_nouns.normal_form\n",
    "                                .apply(self._extract_norm_ending))\n",
    "\n",
    "        undefined_ending_mask = (nouns.norm_ending.isnull() |\n",
    "                                 nouns.ending.isnull())\n",
    "        thrown = list(set(nouns[undefined_ending_mask].word))\n",
    "\n",
    "        nouns = nouns[~undefined_ending_mask]\n",
    "        nouns['declension_type'] = 1\n",
    "        # adjectives.norm_ending.replace(            self.norm_endings_nums)\n",
    "\n",
    "        nouns['label'] = nouns.ending.map(num_by_end)\n",
    "        thrown.extend(nouns[nouns.label.isnull()].word)\n",
    "        nouns = nouns[~nouns.label.isnull()]\n",
    "\n",
    "        df.loc[nouns.index, 'declension_type'] = nouns['declension_type']\n",
    "        df.declension_type = df.declension_type.astype(int)\n",
    "        df['label'] = -1\n",
    "        df.loc[nouns.index, 'label'] = nouns.label\n",
    "        df.loc[nouns.index, 'is_target'] = True\n",
    "        _print_thrown(thrown, Loc.temp_path / \"noun_undefined_ending.txt\")\n",
    "        return [df]\n",
    "\n",
    "    @staticmethod\n",
    "    def build_index_from_src(src_df):\n",
    "        df = src_df.loc[src_df.is_target][[\n",
    "            'word_id', 'sentence_id', 'declension_type', 'label']].copy()\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.index.name = 'sample_id'\n",
    "        df['split'] = train_display_test_split(df)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.corpus.corpus_reader import CorpusReader\n",
    "selector = NounAgreementTrainIndexBuilder()\n",
    "source = Loc.corpus_path / 'prepare/balanced/books&pub_60K_balanced_feat.zip'\n",
    "reader = CorpusReader(source)\n",
    "toc = reader.get_toc()\n",
    "frame_index_in_corpus = 0\n",
    "frame = reader.get_frames().first()\n",
    "toc_row = toc.iloc[frame_index_in_corpus].to_dict()\n",
    "frame_index_in_corpus += 1\n",
    "dfs = selector.select(source, frame, toc_row)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2414"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].is_target.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49971"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
