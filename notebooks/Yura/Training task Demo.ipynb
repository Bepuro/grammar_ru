{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8387a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from tg.common.ml import batched_training as bt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399df843",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc93eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    split\n",
       "0      0  display\n",
       "1      0    train\n",
       "2      0    train\n",
       "3      0    train\n",
       "4      0    train"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yo_fluq_ds import *\n",
    "\n",
    "def get_binary_classification_bundle():\n",
    "    ds = datasets.load_breast_cancer()\n",
    "    features = pd.DataFrame(ds['data'], columns=ds['feature_names'])\n",
    "    df = pd.DataFrame(ds['target'], columns=['label'])\n",
    "    df['split'] = bt.train_display_test_split(df, 0.2, 0.2, 'label')\n",
    "    bundle = bt.DataBundle(index=df, features=features)\n",
    "    return bundle\n",
    "\n",
    "get_binary_classification_bundle().index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8947cae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_binary_classification_bundle().features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59c904e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TaskFactory' from 'tg.grammar_ru.ml.components.training_task_factory' (/home/yura/Desktop/repos/grammar_ru_private/grammar_ru/tg/grammar_ru/ml/components/training_task_factory/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrammar_ru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_task_factory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TaskFactory, Conventions\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dft\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_extractor\u001b[39m():\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TaskFactory' from 'tg.grammar_ru.ml.components.training_task_factory' (/home/yura/Desktop/repos/grammar_ru_private/grammar_ru/tg/grammar_ru/ml/components/training_task_factory/__init__.py)"
     ]
    }
   ],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import TaskFactory, Conventions\n",
    "from tg.common.ml import dft\n",
    "\n",
    "def get_feature_extractor():\n",
    "    feature_extractor = (bt.PlainExtractor\n",
    "                 .build('features')\n",
    "                 .index('features')\n",
    "                 .apply(transformer = dft.DataFrameTransformerFactory.default_factory())\n",
    "                )\n",
    "    return feature_extractor\n",
    "    \n",
    "def get_binary_label_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                   .build(Conventions.LabelFrame)\n",
    "                   .index()\n",
    "                   .apply(take_columns=['label'], transformer=None)\n",
    "                  )\n",
    "    return label_extractor\n",
    "\n",
    "def test_extractor(extractor, bundle):\n",
    "    extractor.fit(bundle)\n",
    "    return extractor.extract(bundle)\n",
    "\n",
    "db = get_binary_classification_bundle()\n",
    "idb = bt.IndexedDataBundle(db.index, db)\n",
    "test_extractor( get_feature_extractor(), idb).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b694854",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_extractor(get_binary_label_extractor(), idb).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa76c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ClassificationNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, sample):\n",
    "        super(ClassificationNetwork, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(sample['features'].shape[1], hidden_size)\n",
    "        self.output = torch.nn.Linear(hidden_size, sample['label'].shape[1])\n",
    "\n",
    "    def forward(self, input):\n",
    "        X = input['features']\n",
    "        X = torch.tensor(X.astype(float).values).float()\n",
    "        X = self.hidden(X)\n",
    "        X = torch.sigmoid(X)\n",
    "        X = self.output(X)\n",
    "        X = torch.sigmoid(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from tg.common import Logger\n",
    "Logger.disable()\n",
    "\n",
    "class ClassificationTask(TaskFactory):\n",
    "    def create_task(self, data, env):\n",
    "        metrics = bt.MetricPool().add_sklearn(roc_auc_score)\n",
    "        self.instantiate_default_task(epoch_count=10, batch_size=1000, mini_batch_size=None, metric_pool=metrics)\n",
    "        self.setup_batcher(data, [get_feature_extractor(), get_binary_label_extractor()])\n",
    "        self.setup_model(lambda _, sample: ClassificationNetwork(100, sample))\n",
    "        \n",
    "task = ClassificationTask()\n",
    "result = task.run(get_binary_classification_bundle())\n",
    "pd.DataFrame(result['output']['history']).set_index('iteration').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a241c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.common.ml.batched_training.torch import networks as btn\n",
    "\n",
    "class ClassificationTask(TaskFactory):\n",
    "    def create_task(self, data, env):\n",
    "        metrics = bt.MetricPool().add_sklearn(roc_auc_score)\n",
    "        self.instantiate_default_task(epoch_count=10, batch_size=1000, mini_batch_size=None, metric_pool=metrics)\n",
    "        self.setup_batcher(data, [get_feature_extractor(), get_binary_label_extractor()])\n",
    "        network_factory = btn.FullyConnectedNetwork.Factory([100],output='label').prepend_extraction('features')\n",
    "        self.setup_model(network_factory)\n",
    "        \n",
    "task = ClassificationTask()\n",
    "result = task.run(get_binary_classification_bundle())\n",
    "pd.DataFrame(result['output']['history']).set_index('iteration').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25ab06",
   "metadata": {},
   "source": [
    "## Multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabel_classification_bundle():\n",
    "    ds = datasets.load_iris()\n",
    "    features = pd.DataFrame(ds['data'], columns=ds['feature_names'])\n",
    "    df = pd.DataFrame(ds['target_names'][ds['target']], columns = ['label'])\n",
    "    df['split'] = bt.train_display_test_split(df, 0.2, 0.2, 'label')\n",
    "    bundle = bt.DataBundle(index=df, features=features)\n",
    "    return bundle\n",
    "    \n",
    "get_multilabel_classification_bundle().index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ce778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabel_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                   .build(Conventions.LabelFrame)\n",
    "                   .index()\n",
    "                   .apply(take_columns=['label'], transformer=dft.DataFrameTransformerFactory.default_factory())\n",
    "                  )\n",
    "    return label_extractor\n",
    "\n",
    "db = get_multilabel_classification_bundle()\n",
    "idb = bt.IndexedDataBundle(db.index, db)\n",
    "test_extractor( get_multilabel_extractor(), idb).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80adf129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassMetrics(bt.Metric):\n",
    "    def __init__(self, add_accuracy = True, add_rating = False):\n",
    "        self.add_accuracy = add_accuracy\n",
    "        self.add_rating = add_rating\n",
    "    \n",
    "    def get_names(self):\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append('accuracy')\n",
    "        if self.add_rating:\n",
    "            result.append('rating')\n",
    "        return result\n",
    "    \n",
    "    def measure(self, df, _):\n",
    "        prefix = 'true_label_'\n",
    "        labels = []\n",
    "        for c in df.columns:\n",
    "            if c.startswith(prefix):\n",
    "                labels.append(c.replace(prefix,''))\n",
    "\n",
    "        def ustack(df, prefix, cols, name):\n",
    "            df = df[[prefix+c for c in cols]]\n",
    "            df.columns=[c for c in cols]\n",
    "            df = df.unstack().to_frame(name)\n",
    "            return df\n",
    "\n",
    "        predicted = ustack(df, 'predicted_label_', labels, 'predicted')\n",
    "        true = ustack(df, 'true_label_', labels, 'true')\n",
    "        df = predicted.merge(true, left_index=True, right_index=True).reset_index()\n",
    "        df.columns=['label','sample','predicted','true']\n",
    "        df = df.feed(fluq.add_ordering_column('sample',('predicted',False), 'predicted_rating'))\n",
    "\n",
    "        match = (df.loc[df.predicted_rating==0].set_index('sample').true>0.5)\n",
    "        rating = df.loc[df.true>0.5].set_index('sample').predicted_rating\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append(match.mean())\n",
    "        if self.add_rating:\n",
    "            result.append(rating.mean())\n",
    "        return result\n",
    "\n",
    "\n",
    "class ClassificationTask(TaskFactory):\n",
    "    def create_task(self, data, env):\n",
    "        metrics = bt.MetricPool().add(MulticlassMetrics())\n",
    "        self.instantiate_default_task(epoch_count=20, batch_size=10000, mini_batch_size=None, metric_pool=metrics)\n",
    "        self.setup_batcher(data, [get_feature_extractor(), get_multilabel_extractor()])\n",
    "        self.setup_model(lambda _, sample: ClassificationNetwork(20, sample), learning_rate=1)\n",
    "        \n",
    "task = ClassificationTask()\n",
    "result = task.run(get_multilabel_classification_bundle())\n",
    "pd.DataFrame(result['output']['history']).set_index('iteration').plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
