{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39dda17-d667-4b97-b0c4-e8dc8a5c3c1a",
   "metadata": {},
   "source": [
    "Решаем задачу поиска ошибки согласования рода.\n",
    "Будем предсказывать род слова по его контексту.\n",
    "Построен бандл.\n",
    "\n",
    "Хотим построить батч. \n",
    "\n",
    "В нем должны быть признаки pymorphy. Разумеется, без рода самого слова.\n",
    "Без slovnet'а потому что slovnet плохо работает на предложениях с ошибками.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433e8db-3a17-49ff-b43c-be9e2712b137",
   "metadata": {},
   "source": [
    "Посмотрим как работает CoreExtractor - сущность, которая по слову вернет все признаки. Умеет работать с любыми индексами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c218ef-19f2-4ec6-bda9-10874a72cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from yo_fluq_ds import *\n",
    "from tg.common.ml import batched_training as bt\n",
    "from tg.common import DataBundle, Loc\n",
    "from tg.common.ml.batched_training import IndexedDataBundle\n",
    "from tg.grammar_ru.ml.components.core_extractor.extractor import CoreExtractor\n",
    "from tg.grammar_ru.ml.components.plain_context_builder import PlainContextBuilder\n",
    "from tg.grammar_ru.ml.components.contextual_binding import ContextualBinding, ContextualNetworkType\n",
    "from tg.common.ml.batched_training import mirrors as btm\n",
    "from tg.common.ml.batched_training import Batcher\n",
    "from tg.grammar_ru.common import Separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626fd51f-c7bf-4178-b988-24fde39ab4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBundle.load(Loc.data_cache_path/'bundles/grammatical_gender/toy')\n",
    "# tiny_index = db.index[db.index.sentence_id < 10]\n",
    "# tiny_db = DataBundle(**{name: df.loc[tiny_index.index]\n",
    "#                      for name, df in db.data_frames.items()})\n",
    "# db = tiny_db\n",
    "idb = IndexedDataBundle(db.index, db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba59cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><span title=\"0\"\">Штабс-капитан <span title=\"1\"\">П<span title=\"2\"\">. <span title=\"3\"\">Н<span title=\"4\"\">. <span title=\"5\"\">Нестеров <span title=\"6\"\">на <span title=\"7\"\">днях<span title=\"8\"\">, <span title=\"9\"\">увидев <span title=\"10\"\">в <span title=\"11\"\">районе <span title=\"12\"\">Желтиева<span title=\"13\"\">, <span title=\"14\"\">в <span title=\"15\"\">Галиции<span title=\"16\"\">, <span title=\"17\"\">летящий <span title=\"18\"\">над <span title=\"19\"\">нашим <span title=\"20\"\">расположением <span title=\"21\"\">австрийский <span title=\"22\"\">аэроплан<span title=\"23\"\">, <span title=\"24\"\">собиравшийся <span title=\"25\"\">бросить <span title=\"26\"\">бомбы<span title=\"27\"\">, <span title=\"28\"\">взлетел <span title=\"29\"\">на <span title=\"30\"\">воздух<span title=\"31\"\">, <span title=\"32\"\">атаковал <span title=\"33\"\">неприятеля <span title=\"34\"\">и <span title=\"35\"\">протаранил <span title=\"36\"\">неприятельский <span title=\"37\"\">аппарат<span title=\"38\"\">, <span title=\"39\"\">предотвратив <span title=\"40\"\">жертвы <span title=\"41\"\">в <span title=\"42\"\">наших <span title=\"43\"\">войсках<span title=\"44\"\">. </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Separator.Viewer().tooltip(\"word_id\").to_html_display(\n",
    "    idb.bundle.src.loc[idb.bundle.src.sentence_id == 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c81593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'pymorphy', 'slovnet', 'src', 'syntax_closure', 'syntax_fixes', 'syntax_stats'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.data_frames.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28665d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158b9046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_id  sentence_id  label    split\n",
       "sample_id                                      \n",
       "0                0            0      0  display\n",
       "1                1            0      1    train\n",
       "2                3            0      1    train\n",
       "3                5            0      0     test\n",
       "4                7            0      0     test"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8655fc-675d-4b12-9719-a61c44ee347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>display</td>\n",
       "      <td>Штабс-капитан</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>П</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Н</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Нестеров</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>днях</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>районе</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>Желтиева</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Галиции</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>летящий</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>display</td>\n",
       "      <td>нашим</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id  label    split           word\n",
       "0        0            0      0  display  Штабс-капитан\n",
       "1        1            0      1    train              П\n",
       "2        3            0      1    train              Н\n",
       "3        5            0      0     test       Нестеров\n",
       "4        7            0      0     test           днях\n",
       "5       11            0      0    train         районе\n",
       "6       12            0      1     test       Желтиева\n",
       "7       15            0      1    train        Галиции\n",
       "8       17            0      0    train        летящий\n",
       "9       19            0      3  display          нашим"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index.head(10).merge(\n",
    "    db.data_frames['src'][['word_id', 'word']], on='word_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6251a41-9daf-4fd3-a354-0b1033e41d97",
   "metadata": {},
   "source": [
    "CoreExtractor принимает список extractor'ов и применяет их к бандлу. Потом нужно подать его ContextualBinding. TODO да?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e46912",
   "metadata": {},
   "source": [
    "##### Пример CoreExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9762bb8-60af-42f0-b9fb-d029b374cc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 06:09:29.355894+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-11-18 06:09:29.633886+00:00 INFO: Success\n",
      "2022-11-18 06:09:29.635888+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-11-18 06:09:29.836883+00:00 INFO: Success\n",
      "2022-11-18 06:09:29.837883+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-11-18 06:09:29.916883+00:00 INFO: Success\n",
      "2022-11-18 06:09:29.917883+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-11-18 06:09:29.981900+00:00 INFO: Success\n",
      "2022-11-18 06:09:29.982884+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-11-18 06:09:30.071885+00:00 INFO: Success\n"
     ]
    }
   ],
   "source": [
    "core = CoreExtractor(allow_list=['pymorphy'])  # TODO что делает allowlist\n",
    "core.fit(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae03f86-7a4a-47e9-9aa9-d8f58ca27c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pymorphy', False),\n",
       " ('slovnet_morph', False),\n",
       " ('slovnet_syntax', False),\n",
       " ('syntax_fixes', False),\n",
       " ('syntax_stats', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core.extractors.keys()\n",
    "[(e_name, e.disabled) for e_name, e in core.extractors.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b925e63b-dd22-434e-8bee-22488e67463b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pymorphy_score</th>\n",
       "      <th>pymorphy_delta_score</th>\n",
       "      <th>pymorphy_alternatives</th>\n",
       "      <th>pymorphy_POS_NOUN</th>\n",
       "      <th>pymorphy_POS_ADJF</th>\n",
       "      <th>pymorphy_POS_VERB</th>\n",
       "      <th>pymorphy_POS_PRTF</th>\n",
       "      <th>pymorphy_POS_PRTS</th>\n",
       "      <th>pymorphy_POS_ADJS</th>\n",
       "      <th>pymorphy_animacy_inan</th>\n",
       "      <th>...</th>\n",
       "      <th>syntax_fixes_root_Picked</th>\n",
       "      <th>syntax_fixes_cycle_status_No</th>\n",
       "      <th>syntax_fixes_cycle_status_Broken</th>\n",
       "      <th>syntax_fixes_cycle_status_Yes</th>\n",
       "      <th>syntax_stats_descendants_relative</th>\n",
       "      <th>syntax_stats_children</th>\n",
       "      <th>syntax_stats_descendants</th>\n",
       "      <th>syntax_stats_sentence_length</th>\n",
       "      <th>syntax_stats_up_depth</th>\n",
       "      <th>syntax_stats_down_depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901142</td>\n",
       "      <td>0.949787</td>\n",
       "      <td>-0.964494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.231461</td>\n",
       "      <td>-0.065904</td>\n",
       "      <td>0.720987</td>\n",
       "      <td>1.253148</td>\n",
       "      <td>-0.880312</td>\n",
       "      <td>0.600570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.069591</td>\n",
       "      <td>-1.616324</td>\n",
       "      <td>6.928503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.314240</td>\n",
       "      <td>1.403946</td>\n",
       "      <td>0.541865</td>\n",
       "      <td>1.253148</td>\n",
       "      <td>-0.066655</td>\n",
       "      <td>-0.046574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.044473</td>\n",
       "      <td>-1.616324</td>\n",
       "      <td>6.534467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.645357</td>\n",
       "      <td>-1.177802</td>\n",
       "      <td>-1.039332</td>\n",
       "      <td>1.253148</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>-1.152873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pymorphy_score  pymorphy_delta_score  pymorphy_alternatives  \\\n",
       "sample_id                                                                \n",
       "0                0.901142              0.949787              -0.964494   \n",
       "1               -3.069591             -1.616324               6.928503   \n",
       "2               -3.044473             -1.616324               6.534467   \n",
       "\n",
       "           pymorphy_POS_NOUN  pymorphy_POS_ADJF  pymorphy_POS_VERB  \\\n",
       "sample_id                                                            \n",
       "0                        1.0                0.0                0.0   \n",
       "1                        1.0                0.0                0.0   \n",
       "2                        1.0                0.0                0.0   \n",
       "\n",
       "           pymorphy_POS_PRTF  pymorphy_POS_PRTS  pymorphy_POS_ADJS  \\\n",
       "sample_id                                                            \n",
       "0                        0.0                0.0                0.0   \n",
       "1                        0.0                0.0                0.0   \n",
       "2                        0.0                0.0                0.0   \n",
       "\n",
       "           pymorphy_animacy_inan  ...  syntax_fixes_root_Picked  \\\n",
       "sample_id                         ...                             \n",
       "0                            0.0  ...                       0.0   \n",
       "1                            1.0  ...                       0.0   \n",
       "2                            1.0  ...                       0.0   \n",
       "\n",
       "           syntax_fixes_cycle_status_No  syntax_fixes_cycle_status_Broken  \\\n",
       "sample_id                                                                   \n",
       "0                                   1.0                               0.0   \n",
       "1                                   1.0                               0.0   \n",
       "2                                   1.0                               0.0   \n",
       "\n",
       "           syntax_fixes_cycle_status_Yes  syntax_stats_descendants_relative  \\\n",
       "sample_id                                                                     \n",
       "0                                    0.0                          -0.231461   \n",
       "1                                    0.0                          -0.314240   \n",
       "2                                    0.0                          -0.645357   \n",
       "\n",
       "           syntax_stats_children  syntax_stats_descendants  \\\n",
       "sample_id                                                    \n",
       "0                      -0.065904                  0.720987   \n",
       "1                       1.403946                  0.541865   \n",
       "2                      -1.177802                 -1.039332   \n",
       "\n",
       "           syntax_stats_sentence_length  syntax_stats_up_depth  \\\n",
       "sample_id                                                        \n",
       "0                              1.253148              -0.880312   \n",
       "1                              1.253148              -0.066655   \n",
       "2                              1.253148               0.510644   \n",
       "\n",
       "           syntax_stats_down_depth  \n",
       "sample_id                           \n",
       "0                         0.600570  \n",
       "1                        -0.046574  \n",
       "2                        -1.152873  \n",
       "\n",
       "[3 rows x 151 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted = core.extract(idb)\n",
    "extracted.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f00c17-5508-43df-a4f7-658810de9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(extracted.columns)  # все признаки из pymorphy, slovnet...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30791cb4",
   "metadata": {},
   "source": [
    "##### ⚹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f5e69-8534-446a-aef2-ab8215001720",
   "metadata": {},
   "source": [
    "* Для каждого слова получили все признаки из pymorphy, slovnet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08039c7d-48b0-4d7a-b5b1-128e1c93ede7",
   "metadata": {},
   "source": [
    "* Нам необходим контекст слова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15527c-77cd-4b6c-8bd8-78e2c825c932",
   "metadata": {},
   "source": [
    "Будем использовать `PlainContextBuilder`.  Он построит двойной индекс.\n",
    "\n",
    "* хотим исключить само слово из контекста, поэтому `include_zero_offset=False`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd869e7c",
   "metadata": {},
   "source": [
    "#### Пример PlainContextBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fb1077c-4498-448a-af52-32a64dfd1de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>another_word_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th>offset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">55755</th>\n",
       "      <th>2</th>\n",
       "      <td>99930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">55784</th>\n",
       "      <th>1</th>\n",
       "      <td>99974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247491 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  another_word_id\n",
       "sample_id offset                 \n",
       "0         1                     1\n",
       "          2                     2\n",
       "          3                     3\n",
       "          4                     4\n",
       "          5                     5\n",
       "...                           ...\n",
       "55755     2                 99930\n",
       "          3                 99931\n",
       "55784     1                 99974\n",
       "          2                 99975\n",
       "          3                 99976\n",
       "\n",
       "[247491 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcb = PlainContextBuilder(include_zero_offset=False,\n",
    "                          left_to_right_contexts_proportion=1)\n",
    "contexts = pcb.build_context(idb, context_size=5)\n",
    "contexts  # TODO у некоторых только offsset == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b064ed1",
   "metadata": {},
   "source": [
    "#### ⚹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394440ba",
   "metadata": {},
   "source": [
    "#### WordContextAssemblyPoint (~ ContextualBinding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c68dbb",
   "metadata": {},
   "source": [
    "Задача AssemblyPoint'a (он же ContextualBinding) - порождать экстракторами батчи в том виде, в котором они будут приняты сетью. Для LSTM будет 3d-тензор. Для Plain-сети будет плоский датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "395fd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_context = ContextualBinding(\n",
    "    name='plain_context',\n",
    "    context_length=3,\n",
    "    network_type=ContextualNetworkType.Plain,\n",
    "    hidden_size=[30],\n",
    "    context_builder=pcb,  # PlainContextBuilder\n",
    "    # extractor=CoreExtractor(join_column='another_word_id'),\n",
    "    extractor=CoreExtractor(\n",
    "        allow_list=['pymorphy'], join_column='another_word_id'),\n",
    "    debug=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92aa50",
   "metadata": {},
   "source": [
    "**Пояснение:**\n",
    "По умолчанию CoreExtractor пытается мерджить по word_id. В нашем случае CoreExtractor отработает после создания PlainContextBuilder'ом двойного индекса. \n",
    "Для добавления признаков слов из контекста будем join'ить по столбцу another_word_id. Поэтому join_column='another_word_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae35c19",
   "metadata": {},
   "source": [
    "Для создания согласованных экстракторов и сетей у AssemblyPoint есть методы create_extractor и create_network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc9aac",
   "metadata": {},
   "source": [
    "У такой сети на последнем слое hidden_size нейронов. Ее выход можно подать в другую сеть, которая будет выдавать вероятности классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afeb414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 06:09:34.036027+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-11-18 06:09:35.913903+00:00 INFO: Success\n",
      "2022-11-18 06:09:35.915908+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-11-18 06:09:37.134524+00:00 INFO: Success\n",
      "2022-11-18 06:09:37.135524+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-11-18 06:09:38.172218+00:00 INFO: Success\n",
      "2022-11-18 06:09:38.173221+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-11-18 06:09:39.087508+00:00 INFO: Success\n",
      "2022-11-18 06:09:39.088501+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-11-18 06:09:39.865184+00:00 INFO: Success\n"
     ]
    }
   ],
   "source": [
    "core_extractor = plain_context.create_extractor(task=None, bundle=idb)\n",
    "core_extractor.fit(idb)\n",
    "# not_batch = core_extractor.extract(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa95cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = plain_context.create_network_factory(\n",
    "    task=None, input=None)  # None это ок. это legacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8a14c",
   "metadata": {},
   "source": [
    "#### Batcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5c17e",
   "metadata": {},
   "source": [
    "Иногда нам нужны фичи контекстов нескольких слов. Например, в задаче поиска антецедентов это местоимение и два существительных - потенциальные антецеденты. Для каждого из этих слов создадим экстрактор (для каждого экстрактора будет отдельная голова нейросети). Batcher примет список этих экстракторов и создаст батч.\n",
    "\n",
    "`+` нам понадобится экстрагировать лейблы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59f8f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import Conventions\n",
    "from tg.common.ml import dft\n",
    "# экстрагирует лейблы. Получается one-hot df. Лейблы пойдут в loss function.\n",
    "\n",
    "\n",
    "def get_multilabel_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                       .build(Conventions.LabelFrame)\n",
    "                       .index()\n",
    "                       .apply(take_columns=['label'], transformer=dft.DataFrameTransformerFactory.default_factory())\n",
    "                       )\n",
    "    return label_extractor\n",
    "\n",
    "\n",
    "def test_extractor(extractor, bundle):\n",
    "    extractor.fit(bundle)\n",
    "    return extractor.extract(bundle)\n",
    "\n",
    "# test_extractor(get_multilabel_extractor(), idb).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a3b06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-18 06:10:05.228230+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-11-18 06:10:05.299226+00:00 INFO: Success\n",
      "2022-11-18 06:10:05.300242+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-11-18 06:10:05.344226+00:00 INFO: Success\n",
      "2022-11-18 06:10:05.345232+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-11-18 06:10:05.370223+00:00 INFO: Success\n",
      "2022-11-18 06:10:05.372223+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-11-18 06:10:05.397244+00:00 INFO: Success\n",
      "2022-11-18 06:10:05.399240+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-11-18 06:10:05.438229+00:00 INFO: Success\n"
     ]
    }
   ],
   "source": [
    "batcher = Batcher(batch_size=10, extractors=[\n",
    "                  core_extractor, get_multilabel_extractor()])\n",
    "batch = batcher.fit_extract(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58f0e209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['index'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b9addb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 30])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = factory.create_network(task=None, input=batch)\n",
    "# при создании сети необходим батч, чтобы TODO\n",
    "network(batch).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47229cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO tsa run_tarining. factory...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9e15e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e710e",
   "metadata": {},
   "source": [
    "Полные данные не помещаются в память локальной машины, но для инициализации сети нужно понять, сколько бывает классов в полных данных. Поэтому сеть инициализируется в BatchedTrainingTask, который выполняется на сервере. \n",
    "\n",
    "Создадим TaskFactory, отправим ее на сервер. Она подтянет данные, создаст BatchedTrainingTask и запустит его.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3cb1d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def _update_sizes_with_argument(argument_name, argument, sizes, modificator):\n",
    "    if argument is None:\n",
    "        return sizes\n",
    "    elif isinstance(argument, torch.Tensor):\n",
    "        return modificator(sizes, argument.shape[1])\n",
    "    elif isinstance(argument, pd.DataFrame):\n",
    "        return modificator(sizes, argument.shape[1])\n",
    "    elif isinstance(argument, int):\n",
    "        return modificator(sizes, argument)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Argument {argument_name} is supposed to be int, Tensor or none, but was `{argument}`\")\n",
    "\n",
    "\n",
    "class FullyConnectedNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 sizes: List[int],\n",
    "                 input: Union[None, torch.Tensor, int] = None,\n",
    "                 output: Union[None, torch.Tensor, int] = None):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        sizes = _update_sizes_with_argument(\n",
    "            'input', input, sizes, lambda s, v: [v] + s)\n",
    "        sizes = _update_sizes_with_argument(\n",
    "            'output', output, sizes, lambda s, v: s + [v])\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(len(sizes) - 1):\n",
    "            self.layers.append(torch.nn.Linear(sizes[i], sizes[i + 1]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        X = input\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "            X = torch.sigmoid(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "# class AssembledModel(torch.nn.Module):\n",
    "#     def __init__(self, head, tail):\n",
    "#         super(AssembledModel, self).__init__()\n",
    "#         self.head = head\n",
    "#         self.tail = tail\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.head(x)\n",
    "#         x = self.tail(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a7189dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.common.ml.batched_training.torch.networks.extracting_network import FeedForwardNetwork\n",
    "\n",
    "class MyNetworkFactory:\n",
    "    def __init__(self, nn_head_factory):\n",
    "        self.nn_head_factory = nn_head_factory\n",
    "\n",
    "    def create_network(self, task, input):  # input is batch ~ sample\n",
    "        nn_head = self.nn_head_factory.create_network(task=None, input=input)\n",
    "        head_out = nn_head(input)\n",
    "        hidden_size = head_out.shape[1]\n",
    "        labels_count = input['label'].shape[1]\n",
    "        nn_tail = FullyConnectedNetwork(\n",
    "            sizes=[3], input=hidden_size, output=labels_count)\n",
    "        return FeedForwardNetwork(nn_head, nn_tail, torch.nn.Softmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f47dc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_network_factory = MyNetworkFactory(factory)\n",
    "assembled_network = assembled_network_factory.create_network(\n",
    "    task=None, input=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0056c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_indices = batcher.get_mini_batch_indices(mini_batch_size = 10, batch = batch)\n",
    "# mini_batch = batcher.get_mini_batch(index = mini_batch_indices[0], batch = batch)\n",
    "# mini_batch['index'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c781561c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.4366, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, input)\n",
    "output.backward()\n",
    "# # Example of target with class probabilities\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.randn(3, 5).softmax(dim=1)\n",
    "# output = loss(input, target)\n",
    "# output.backward()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ffa2a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn, optimizer):\n",
    "    for mini_batch_num, mini_batch_index in enumerate(mini_batch_indices):\n",
    "        mini_batch = batcher.get_mini_batch(index = mini_batch_indices[mini_batch_num], batch = batch)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(mini_batch)\n",
    "        loss = loss_fn(pred, torch.tensor(mini_batch['label'].values))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 100 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{num_batches:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cf4481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 1\n",
    "optimizer = torch.optim.SGD(assembled_network.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(assembled_network, loss, optimizer)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "15015434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label_0  label_1  label_3\n",
       "sample_id                           \n",
       "0              1.0      0.0      0.0\n",
       "1              0.0      1.0      0.0\n",
       "2              0.0      1.0      0.0\n",
       "3              1.0      0.0      0.0\n",
       "4              1.0      0.0      0.0\n",
       "5              1.0      0.0      0.0\n",
       "6              0.0      1.0      0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3f89d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = assembled_network(batch)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edc40451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class ClassificationNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, sample):\n",
    "        super(ClassificationNetwork, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(sample['features'].shape[1], hidden_size)\n",
    "        self.output = torch.nn.Linear(hidden_size, sample['label'].shape[1])\n",
    "\n",
    "    def forward(self, input):\n",
    "        X = input['features']\n",
    "        X = torch.tensor(X.astype(float).values).float()\n",
    "        X = self.hidden(X)\n",
    "        X = torch.sigmoid(X)\n",
    "        X = self.output(X)\n",
    "        X = torch.sigmoid(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import TaskFactory, Conventions\n",
    "from tg.common.ml import dft\n",
    "\n",
    "\n",
    "class MulticlassMetrics(bt.Metric):\n",
    "    def __init__(self, add_accuracy=True, add_rating=False):\n",
    "        self.add_accuracy = add_accuracy\n",
    "        self.add_rating = add_rating\n",
    "\n",
    "    def get_names(self):\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append('accuracy')\n",
    "        if self.add_rating:\n",
    "            result.append('rating')\n",
    "        return result\n",
    "\n",
    "    def measure(self, df, _):\n",
    "        prefix = 'true_label_'\n",
    "        labels = []\n",
    "        for c in df.columns:\n",
    "            if c.startswith(prefix):\n",
    "                labels.append(c.replace(prefix, ''))\n",
    "\n",
    "        def ustack(df, prefix, cols, name):\n",
    "            df = df[[prefix+c for c in cols]]\n",
    "            df.columns = [c for c in cols]\n",
    "            df = df.unstack().to_frame(name)\n",
    "            return df\n",
    "\n",
    "        predicted = ustack(df, 'predicted_label_', labels, 'predicted')\n",
    "        true = ustack(df, 'true_label_', labels, 'true')\n",
    "        df = predicted.merge(true, left_index=True,\n",
    "                             right_index=True).reset_index()\n",
    "        df.columns = ['label', 'sample', 'predicted', 'true']\n",
    "        df = df.feed(fluq.add_ordering_column(\n",
    "            'sample', ('predicted', False), 'predicted_rating'))\n",
    "\n",
    "        match = (df.loc[df.predicted_rating ==\n",
    "                 0].set_index('sample').true > 0.5)\n",
    "        rating = df.loc[df.true > 0.5].set_index('sample').predicted_rating\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append(match.mean())\n",
    "        if self.add_rating:\n",
    "            result.append(rating.mean())\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13188570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabel_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                       .build(Conventions.LabelFrame)\n",
    "                       .index()\n",
    "                       .apply(take_columns=['label'], transformer=dft.DataFrameTransformerFactory.default_factory())\n",
    "                       )\n",
    "    return label_extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-17 06:52:05.716220+00:00 INFO: Training starts. Info: {}\n",
      "2022-11-17 06:52:05.717230+00:00 INFO: Ensuring/loading bundle. Bundle before:\n",
      "<tg.common.ml.batched_training.data_bundle.IndexedDataBundle object at 0x000001F0873B53F0>\n",
      "2022-11-17 06:52:05.718212+00:00 INFO: Bundle loaded\n",
      "{'index': {'shape': (55787, 4), 'index_name': 'sample_id', 'columns': ['word_id', 'sentence_id', 'label', 'split'], 'index': [0, 1, 2, 3, 4, '...']}, 'pymorphy': {'shape': (99977, 16), 'index_name': 'word_id', 'columns': ['normal_form', 'alternatives', 'score', 'delta_score', 'POS', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'slovnet': {'shape': (99977, 17), 'index_name': 'word_id', 'columns': ['POS', 'Animacy', 'Case', 'Gender', 'Number', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'src': {'shape': (99977, 16), 'index_name': None, 'columns': ['word_id', 'sentence_id', 'word_index', 'paragraph_id', 'word_tail', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'syntax_closure': {'shape': (260387, 4), 'index_name': 'entry_id', 'columns': ['word_id', 'syntax_parent_id', 'relation', 'distance'], 'index': [0, 1, 2, 3, 4, '...']}, 'syntax_fixes': {'shape': (99977, 4), 'index_name': 'word_id', 'columns': ['syntax_parent_id', 'root', 'cycle_status', 'correct_root'], 'index': [0, 1, 2, 3, 4, '...']}, 'syntax_stats': {'shape': (99977, 6), 'index_name': 'word_id', 'columns': ['children', 'descendants', 'up_depth', 'down_depth', 'sentence_length', '...'], 'index': [0, 1, 2, 3, 4, '...']}}\n",
      "2022-11-17 06:52:05.720224+00:00 INFO: Index frame is set to index, shape is (55787, 4)\n",
      "2022-11-17 06:52:05.722217+00:00 INFO: Skipping late initialization\n",
      "2022-11-17 06:52:05.726213+00:00 INFO: Preprocessing bundle by batcher\n",
      "2022-11-17 06:52:05.754219+00:00 INFO: Splits: train 39050, test 16737, display 16736\n",
      "2022-11-17 06:52:05.758214+00:00 INFO: New training. Instantiating the system\n",
      "2022-11-17 06:52:05.765231+00:00 INFO: Fitting the transformers\n",
      "2022-11-17 06:52:05.772221+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-11-17 06:52:05.869252+00:00 INFO: Success\n",
      "2022-11-17 06:52:05.871217+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-11-17 06:52:05.937210+00:00 INFO: Success\n",
      "2022-11-17 06:52:05.938231+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-11-17 06:52:05.967203+00:00 INFO: Success\n",
      "2022-11-17 06:52:05.969205+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-11-17 06:52:05.996230+00:00 INFO: Success\n",
      "2022-11-17 06:52:05.997210+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-11-17 06:52:06.039231+00:00 INFO: Success\n",
      "2022-11-17 06:52:06.576672+00:00 INFO: Instantiating model\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\1Education\\grammar_ru\\research\\grammatical_gender\\batch GG.ipynb Ячейка 43\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m task \u001b[39m=\u001b[39m ClassificationTask()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m idb \u001b[39m=\u001b[39m IndexedDataBundle(db\u001b[39m.\u001b[39mindex, db)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m result \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39;49mrun(idb)\n",
      "File \u001b[1;32md:\\1education\\grammar_ru\\tg\\common\\ml\\training_core\\arch.py:78\u001b[0m, in \u001b[0;36mAbstractTrainingTask.run\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, data: Any):\n\u001b[0;32m     77\u001b[0m     env \u001b[39m=\u001b[39m InMemoryTrainingEnvironment()\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_with_environment(data, env)\n\u001b[0;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m env\u001b[39m.\u001b[39mresult\n",
      "File \u001b[1;32md:\\1education\\grammar_ru\\tg\\grammar_ru\\ml\\components\\training_task_factory\\torch_task_factory.py:47\u001b[0m, in \u001b[0;36mTaskFactory.run_with_environment\u001b[1;34m(self, data, env)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_task(data, env)\n\u001b[1;32m---> 47\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask\u001b[39m.\u001b[39;49mrun_with_environment(data, env)\n",
      "File \u001b[1;32md:\\1education\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:354\u001b[0m, in \u001b[0;36mBatchedTrainingTask.run_with_environment\u001b[1;34m(self, _bundle, env)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_with_environment\u001b[39m(\u001b[39mself\u001b[39m, _bundle: Union[\u001b[39mstr\u001b[39m, Path, DataBundle], env: Optional[TrainingEnvironment] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 354\u001b[0m     temp_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_all(_bundle, env)\n\u001b[0;32m    355\u001b[0m     Logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mInitialization completed\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    357\u001b[0m     temp_data\u001b[39m.\u001b[39mtrain_bundle \u001b[39m=\u001b[39m temp_data\u001b[39m.\u001b[39moriginal_ibundle\u001b[39m.\u001b[39mchange_index(temp_data\u001b[39m.\u001b[39msplit\u001b[39m.\u001b[39mtrain)\n",
      "File \u001b[1;32md:\\1education\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:177\u001b[0m, in \u001b[0;36mBatchedTrainingTask._prepare_all\u001b[1;34m(self, bundle, env)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mcontinue_training:\n\u001b[0;32m    176\u001b[0m     Logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mNew training. Instantiating the system\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_instantiate_all(ibundle\u001b[39m.\u001b[39;49mchange_index(split\u001b[39m.\u001b[39;49mtrain))\n\u001b[0;32m    178\u001b[0m     first_iteration \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    179\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\1education\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:125\u001b[0m, in \u001b[0;36mBatchedTrainingTask._instantiate_all\u001b[1;34m(self, ibundle)\u001b[0m\n\u001b[0;32m    122\u001b[0m test_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatcher\u001b[39m.\u001b[39mfit_extract(ibundle)\n\u001b[0;32m    124\u001b[0m Logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mInstantiating model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_handler\u001b[39m.\u001b[39;49minstantiate(\u001b[39mself\u001b[39;49m, test_batch)\n",
      "File \u001b[1;32md:\\1education\\grammar_ru\\tg\\grammar_ru\\ml\\components\\training_task_factory\\torch_model_handler.py:48\u001b[0m, in \u001b[0;36mTorchModelHandler.instantiate\u001b[1;34m(self, task, input)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork_factory\u001b[39m.\u001b[39mcreate_network(task, \u001b[39minput\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork_factory(task, \u001b[39minput\u001b[39;49m)\n\u001b[0;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_ctor\u001b[39m.\u001b[39minstantiate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_ctor()\n",
      "\u001b[1;32md:\\1Education\\grammar_ru\\research\\grammatical_gender\\batch GG.ipynb Ячейка 43\u001b[0m in \u001b[0;36mClassificationTask.create_task.<locals>.<lambda>\u001b[1;34m(_, sample)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstantiate_default_task(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epoch_count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, mini_batch_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, metric_pool\u001b[39m=\u001b[39mmetrics)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_batcher(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# data, [get_feature_extractor(), get_multilabel_extractor()])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     data, [core, get_multilabel_extractor()])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_model(\u001b[39mlambda\u001b[39;00m _, sample: ClassificationNetwork(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m20\u001b[39;49m, sample), learning_rate\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32md:\\1Education\\grammar_ru\\research\\grammatical_gender\\batch GG.ipynb Ячейка 43\u001b[0m in \u001b[0;36mClassificationNetwork.__init__\u001b[1;34m(self, hidden_size, sample)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hidden_size, sample):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39msuper\u001b[39m(ClassificationNetwork, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mLinear(sample[\u001b[39m'\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], hidden_size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/1Education/grammar_ru/research/grammatical_gender/batch%20GG.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mLinear(hidden_size, sample[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "class ClassificationTask(TaskFactory):\n",
    "    def create_task(self, data, env):\n",
    "        metrics = bt.MetricPool().add(MulticlassMetrics())  # TODO epoch_count=20\n",
    "        self.instantiate_default_task(\n",
    "            epoch_count=1, batch_size=10000, mini_batch_size=None, metric_pool=metrics)\n",
    "        self.setup_batcher(\n",
    "            # data, [get_feature_extractor(), get_multilabel_extractor()])\n",
    "            data, [core, get_multilabel_extractor()])\n",
    "        self.setup_model(lambda _, sample: ClassificationNetwork(\n",
    "            20, sample), learning_rate=1)\n",
    "\n",
    "\n",
    "task = ClassificationTask()\n",
    "idb = IndexedDataBundle(db.index, db)\n",
    "result = task.run(idb)\n",
    "# pd.DataFrame(result['output']['history']).set_index('iteration').plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f9e0f",
   "metadata": {},
   "source": [
    "setup_butcher принимает экстракторы. Передадим core? или завернем его в get_feature_extractor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce965d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
